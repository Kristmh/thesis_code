{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f89275a9",
   "metadata": {},
   "source": [
    "# Importsand preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d342db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import datasets\n",
    "import transformers\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b3abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !watch -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6579d707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1+cu117\n",
      "CUDA version: 11.7\n",
      "cuDNN version: 8500\n",
      "Current device: 0\n",
      "Is cuda available: True\n"
     ]
    }
   ],
   "source": [
    "print(f'PyTorch version: {torch.__version__}')  # 1.9.1+cu111\n",
    "print(f'CUDA version: {torch.version.cuda}')  # 11.1\n",
    "print(f'cuDNN version: {torch.backends.cudnn.version()}')  # 8005\n",
    "print(f'Current device: {torch.cuda.current_device()}')  # 0\n",
    "print(f'Is cuda available: {torch.cuda.is_available()}')  # TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30504d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.32.1\n",
      "Datasets version: 2.14.4\n"
     ]
    }
   ],
   "source": [
    "print(f'Transformers version: {transformers.__version__}')\n",
    "print(f'Datasets version: {datasets.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f96c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent a warning related to the tokenization process in the transformers library. \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "# Makes CUDA operations synchronous\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855ee0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 14 09:05:13 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti      On | 00000000:01:00.0 Off |                  N/A |\n",
      "| 24%   44C    P2               63W / 250W|    949MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti      On | 00000000:23:00.0 Off |                  N/A |\n",
      "| 43%   71C    P2              244W / 250W|  10431MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti      On | 00000000:41:00.0 Off |                  N/A |\n",
      "| 44%   72C    P2              243W / 250W|  10431MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti      On | 00000000:61:00.0 Off |                  N/A |\n",
      "| 37%   63C    P2              239W / 250W|  10431MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti      On | 00000000:81:00.0 Off |                  N/A |\n",
      "| 22%   40C    P2               49W / 250W|   1307MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti      On | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 22%   30C    P8               18W / 250W|      5MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti      On | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 22%   35C    P8               21W / 250W|      5MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti      On | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 40%   66C    P2              247W / 250W|  10431MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    1   N/A  N/A   1390515      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "|    2   N/A  N/A   1390516      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "|    3   N/A  N/A   1390517      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "|    7   N/A  N/A   1390518      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Find the GPU with the least memory usage.\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c72ee9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 |   0% |  8% |\n",
      "|  1 | 100% | 93% |\n",
      "|  2 | 100% | 93% |\n",
      "|  3 | 100% | 93% |\n",
      "|  4 |   0% | 12% |\n",
      "|  5 |   0% |  0% |\n",
      "|  6 |   0% |  0% |\n",
      "|  7 | 100% | 93% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 |   0% |  8% |\n",
      "|  1 | 100% | 93% |\n",
      "|  2 | 100% | 93% |\n",
      "|  3 | 100% | 93% |\n",
      "|  4 |   0% | 12% |\n",
      "|  5 |   0% |  0% |\n",
      "|  6 |   0% |  1% |\n",
      "|  7 | 100% | 93% |\n"
     ]
    }
   ],
   "source": [
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    # free unreferenced tensors from the GPU memory.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc89bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>issue url ads httpswwwgultecompaparazzipics764...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>browser firefox mobile 1170 uaheader mozilla50...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>consider the file frontendsbenchmarksverificat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in a repository with many files it appears tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>look at other webdrivers and make sure that ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226982</th>\n",
       "      <td>create a personal page for yourself and link i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226983</th>\n",
       "      <td>when you run the trial it will set areas on fi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226984</th>\n",
       "      <td>the navigator of the wiki should be edited and...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226985</th>\n",
       "      <td>javascript code or see if possible without tha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226986</th>\n",
       "      <td>that can be opened from a dropdown menu</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226987 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean  label\n",
       "0       issue url ads httpswwwgultecompaparazzipics764...      0\n",
       "1       browser firefox mobile 1170 uaheader mozilla50...      0\n",
       "2       consider the file frontendsbenchmarksverificat...      0\n",
       "3       in a repository with many files it appears tha...      0\n",
       "4       look at other webdrivers and make sure that ex...      0\n",
       "...                                                   ...    ...\n",
       "226982  create a personal page for yourself and link i...      2\n",
       "226983  when you run the trial it will set areas on fi...      2\n",
       "226984  the navigator of the wiki should be edited and...      2\n",
       "226985  javascript code or see if possible without tha...      2\n",
       "226986            that can be opened from a dropdown menu      2\n",
       "\n",
       "[226987 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"csv/priority_high_med_low_clean.csv\" , index_col = 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f26fa5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller and faster than bert.\n",
    "base_model_id = \"distilbert-base-uncased\"\n",
    "\n",
    "epochs = 5 #Number of full cyles through the training set.\n",
    "num_labels = 3 #Number of labels, high, med, low priority.\n",
    "learning_rate = 5e-5 # Rate the model updates based on the data its trained on.\n",
    "train_batch_size = 16 # Number of training examples in one iteration.\n",
    "eval_batch_size = 32 # Number evalutaion examples in on iteratoion.\n",
    "save_strategy = \"no\" # Should the model be saved automatically during training.\n",
    "save_steps = 500 # How often to save the model during training. No effect since no over.\n",
    "logging_steps = 100\n",
    "model_dir = \"./model\" #Where to save model\n",
    "\n",
    "# Use early stopping to prevent overfitting\n",
    "#load_best_model_at_end=True\n",
    "#metric_for_best_model=\"eval_loss\"\n",
    "#greater_is_better=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c48ccefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split dataframe into three parts: training, validation and testing.\n",
    "def train_validate_test_split(df, train_percent=.8, validate_percent=.1, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    # Shuffle index of dataframe\n",
    "    perm = np.random.permutation(df.index)\n",
    "    \n",
    "    df_length = len(df.index)\n",
    "    \n",
    "    # Number of row in training set\n",
    "    train_end = int(train_percent * df_length)\n",
    "    # Number of rows in validate set\n",
    "    validate_end = int(validate_percent * df_length) + train_end\n",
    "    \n",
    "    # From start to train end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    # From train_end to validate_end\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    # From validate to the last row in dataframe.\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "830cb234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops rows with missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "365a025e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>issue url ads httpswwwgultecompaparazzipics764...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>browser firefox mobile 1170 uaheader mozilla50...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>consider the file frontendsbenchmarksverificat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>in a repository with many files it appears tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>look at other webdrivers and make sure that ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226982</th>\n",
       "      <td>226982</td>\n",
       "      <td>create a personal page for yourself and link i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226983</th>\n",
       "      <td>226983</td>\n",
       "      <td>when you run the trial it will set areas on fi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226984</th>\n",
       "      <td>226984</td>\n",
       "      <td>the navigator of the wiki should be edited and...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226985</th>\n",
       "      <td>226985</td>\n",
       "      <td>javascript code or see if possible without tha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226986</th>\n",
       "      <td>226986</td>\n",
       "      <td>that can be opened from a dropdown menu</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226987 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                         text_clean  label\n",
       "0            0  issue url ads httpswwwgultecompaparazzipics764...      0\n",
       "1            1  browser firefox mobile 1170 uaheader mozilla50...      0\n",
       "2            2  consider the file frontendsbenchmarksverificat...      0\n",
       "3            3  in a repository with many files it appears tha...      0\n",
       "4            4  look at other webdrivers and make sure that ex...      0\n",
       "...        ...                                                ...    ...\n",
       "226982  226982  create a personal page for yourself and link i...      2\n",
       "226983  226983  when you run the trial it will set areas on fi...      2\n",
       "226984  226984  the navigator of the wiki should be edited and...      2\n",
       "226985  226985  javascript code or see if possible without tha...      2\n",
       "226986  226986            that can be opened from a dropdown menu      2\n",
       "\n",
       "[226987 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resets the index after dropping rows\n",
    "data.reset_index(inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29193757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drops the index col, better for managint the data.\n",
    "data.drop(columns= [\"index\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d65133a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>issue url ads httpswwwgultecompaparazzipics764...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>browser firefox mobile 1170 uaheader mozilla50...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>consider the file frontendsbenchmarksverificat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in a repository with many files it appears tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>look at other webdrivers and make sure that ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226982</th>\n",
       "      <td>create a personal page for yourself and link i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226983</th>\n",
       "      <td>when you run the trial it will set areas on fi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226984</th>\n",
       "      <td>the navigator of the wiki should be edited and...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226985</th>\n",
       "      <td>javascript code or see if possible without tha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226986</th>\n",
       "      <td>that can be opened from a dropdown menu</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226987 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean  label\n",
       "0       issue url ads httpswwwgultecompaparazzipics764...      0\n",
       "1       browser firefox mobile 1170 uaheader mozilla50...      0\n",
       "2       consider the file frontendsbenchmarksverificat...      0\n",
       "3       in a repository with many files it appears tha...      0\n",
       "4       look at other webdrivers and make sure that ex...      0\n",
       "...                                                   ...    ...\n",
       "226982  create a personal page for yourself and link i...      2\n",
       "226983  when you run the trial it will set areas on fi...      2\n",
       "226984  the navigator of the wiki should be edited and...      2\n",
       "226985  javascript code or see if possible without tha...      2\n",
       "226986            that can be opened from a dropdown menu      2\n",
       "\n",
       "[226987 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb0e425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60% trainig, 20% validate, 20% test. Seed None.\n",
    "# Test 80-10-10 and 70-15-15\n",
    "train , validate , test = train_validate_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "024bdd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index(\"label\" , inplace = True)\n",
    "validate.set_index(\"label\" , inplace = True)\n",
    "test.set_index(\"label\" , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cb16842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>todo x decide on maximum acceptable wind and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the current apaeval conda environment contains...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hallo beim letzten update 130 alpha 4 habe ich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>while scanning the cmsweb weekly report i almo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>error message is ascii codec cant encode chara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is your feature request related to a problem p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>imagehttpsuserimagesgithubusercontentcom353649...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whats the problem i entered all my blogs and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>describe the bug custom user text styles not a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>server doesnt quit resulting in a timeout on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22700 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_clean\n",
       "label                                                   \n",
       "1      todo x decide on maximum acceptable wind and r...\n",
       "2      the current apaeval conda environment contains...\n",
       "0      hallo beim letzten update 130 alpha 4 habe ich...\n",
       "1      while scanning the cmsweb weekly report i almo...\n",
       "1      error message is ascii codec cant encode chara...\n",
       "...                                                  ...\n",
       "1      is your feature request related to a problem p...\n",
       "1      imagehttpsuserimagesgithubusercontentcom353649...\n",
       "1      whats the problem i entered all my blogs and t...\n",
       "1      describe the bug custom user text styles not a...\n",
       "1      server doesnt quit resulting in a timeout on t...\n",
       "\n",
       "[22700 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a32ee5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 22700\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 181589\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 22698\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert from Pandas DataFrame to Hugging Face datasets\n",
    "tds = Dataset.from_pandas(train)\n",
    "vds = Dataset.from_pandas(validate)\n",
    "testds = Dataset.from_pandas(test)\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds[\"test\"] = testds\n",
    "ds[\"train\"] = tds\n",
    "ds[\"validate\"] = vds\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "386b14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ds[\"train\"]\n",
    "valid_dataset = ds[\"validate\"]\n",
    "test_ds = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3263a36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_clean': 'a hrefhttpsgithubcomgooglecodeexporterimg srchttpsavatarsgithubusercontentcomu9614759v3 alignleft width96 height96 hspace10imga issue by googlecodeexporterhttpsgithubcomgooglecodeexporter monday jul 27 2015 at 0320 gmt originally opened as httpsgithubcomadamsmjyawlissues29 in the attached example when logged in as user stephan deallocating the only work item leads to the message the attempt to deallocate the selected workitem was unsuccessful please check the log files for details original issue reported on codegooglecom by arthurtegmailcom on 21 jul 2008 at 833 attachments newtest20xmlhttpsstoragegoogleapiscomgooglecodeattachmentsyawlissue29comment0newtest20xml newtest20backuphttpsstoragegoogleapiscomgooglecodeattachmentsyawlissue29comment0newtest20backup',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7ef1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbffc393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_id, num_labels=num_labels)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "# optim = torch.optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484feadf",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d90b52d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76dfffd",
   "metadata": {},
   "source": [
    "    Tokenizing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c848144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c62199c8d0f40608b6e4c4795234950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/181589 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e71b1e16ad4be0bc39bff377d804bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22698 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81664485a61c4ec4b839a549dfff6608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenize the dataset to the correct input for the transformer model.\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text_clean\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "valid_dataset = valid_dataset.map(tokenize, batched=True, batch_size=len(valid_dataset))\n",
    "test_dataset = test_ds.map(tokenize, batched=True, batch_size=len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10c7769",
   "metadata": {},
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a5a7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    save_strategy=save_strategy,\n",
    "    save_steps=save_steps,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "318fc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    " trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b5578f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56750' max='56750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56750/56750 4:59:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>0.822433</td>\n",
       "      <td>0.610054</td>\n",
       "      <td>[0.65928391 0.60354945 0.55523796]</td>\n",
       "      <td>[0.6512867  0.65288744 0.52372607]</td>\n",
       "      <td>[0.66747996 0.56114438 0.59078467]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.750800</td>\n",
       "      <td>0.813862</td>\n",
       "      <td>0.616706</td>\n",
       "      <td>[0.65451163 0.61747255 0.57420591]</td>\n",
       "      <td>[0.7019154  0.63332401 0.52216135]</td>\n",
       "      <td>[0.61310561 0.60239521 0.63777372]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.607400</td>\n",
       "      <td>0.907922</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>[0.66541837 0.6211878  0.55563876]</td>\n",
       "      <td>[0.67028174 0.62444534 0.5473591 ]</td>\n",
       "      <td>[0.66062507 0.61796407 0.56417275]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>1.031681</td>\n",
       "      <td>0.619570</td>\n",
       "      <td>[0.66571019 0.62349096 0.55882998]</td>\n",
       "      <td>[0.68562985 0.62503343 0.53824482]</td>\n",
       "      <td>[0.6469153  0.62195609 0.58105231]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.305200</td>\n",
       "      <td>1.315833</td>\n",
       "      <td>0.613138</td>\n",
       "      <td>[0.66256143 0.6210771  0.53958989]</td>\n",
       "      <td>[0.67556146 0.60331201 0.5450737 ]</td>\n",
       "      <td>[0.65005228 0.63992016 0.53421533]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=56750, training_loss=0.6061593800011186, metrics={'train_runtime': 17963.1601, 'train_samples_per_second': 50.545, 'train_steps_per_second': 3.159, 'total_flos': 1.2027525717293568e+17, 'train_loss': 0.6061593800011186, 'epoch': 5.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac7267",
   "metadata": {},
   "source": [
    "* Training loss: Difference between the predictons made by the model on the training dataset vs on the actual data.\n",
    "* Validation loss: how well the model functions on unseen data.\n",
    "* Accuracy: How much the model gets correct. number of correct Prediction / total number of predictions.\n",
    "* F1: consider both precision and recall. \n",
    "* Precision: Accuracy of positive predictions. Percison TP = TP + FP. How often the model is correct.\n",
    "* Recall: True positive rate. how many items the model gets correct from the total amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c34a7fd",
   "metadata": {},
   "source": [
    "### Training loss decreases, valdiation loss increases = Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a791423d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1420' max='710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [710/710 04:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate valdiation set\n",
    "eval_result = trainer.evaluate(eval_dataset=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88295878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.6131377213851441\n",
      "\n",
      "eval_f1 = [0.66256143 0.6210771  0.53958989]\n",
      "\n",
      "eval_loss = 1.3158326148986816\n",
      "\n",
      "eval_precision = [0.67556146 0.60331201 0.5450737 ]\n",
      "\n",
      "eval_recall = [0.65005228 0.63992016 0.53421533]\n",
      "\n",
      "eval_runtime = 144.9896\n",
      "\n",
      "eval_samples_per_second = 156.549\n",
      "\n",
      "eval_steps_per_second = 4.897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(eval_result.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dce22454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data set\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5970cfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.6056387665198237\n",
      "\n",
      "eval_f1 = [0.65838143 0.61134924 0.52865296]\n",
      "\n",
      "eval_loss = 1.3424071073532104\n",
      "\n",
      "eval_precision = [0.66894075 0.59053269 0.54061401]\n",
      "\n",
      "eval_recall = [0.6481503  0.633687   0.51720973]\n",
      "\n",
      "eval_runtime = 145.3142\n",
      "\n",
      "eval_samples_per_second = 156.213\n",
      "\n",
      "eval_steps_per_second = 4.886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(test_results.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c52c8395",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir + \"_local\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cac76c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "    \n",
    "classifier = pipeline(\"text-classification\", model=\"./model_local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "534615c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee71c0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_2', 'score': 0.9661545753479004}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this does not need to be done fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3978b8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9975225329399109}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this is super important\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcb83892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9940073490142822}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this bug has super high impact on the project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a082ef",
   "metadata": {},
   "source": [
    "## Important to delete large objects to free memory \n",
    "del train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44bc1927",
   "metadata": {},
   "outputs": [],
   "source": [
    "del valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d547dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff22f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f2be48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 14 14:12:24 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti      On | 00000000:01:00.0 Off |                  N/A |\n",
      "| 24%   44C    P2               63W / 250W|    949MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti      On | 00000000:23:00.0 Off |                  N/A |\n",
      "| 43%   69C    P2              252W / 250W|  10431MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti      On | 00000000:41:00.0 Off |                  N/A |\n",
      "| 44%   70C    P2              252W / 250W|  10431MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti      On | 00000000:61:00.0 Off |                  N/A |\n",
      "| 37%   61C    P2              245W / 250W|  10431MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti      On | 00000000:81:00.0 Off |                  N/A |\n",
      "| 24%   44C    P2               52W / 250W|   1307MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti      On | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 22%   31C    P8               18W / 250W|      5MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti      On | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 43%   64C    P2               94W / 250W|   1215MiB / 11264MiB |     15%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti      On | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 39%   65C    P2              250W / 250W|  10431MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    1   N/A  N/A   1390515      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "|    2   N/A  N/A   1390516      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "|    3   N/A  N/A   1390517      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "|    6   N/A  N/A     18374      C   .../home/krimhau/miniconda3/bin/python     1210MiB |\n",
      "|    7   N/A  N/A   1390518      C   ...ml/home/limeng/torch_env/bin/python    10424MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff4d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
