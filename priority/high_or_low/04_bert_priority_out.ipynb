{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f89275a9",
   "metadata": {
    "papermill": {
     "duration": 0.116657,
     "end_time": "2023-11-22T09:31:03.529493",
     "exception": false,
     "start_time": "2023-11-22T09:31:03.412836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importsand preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d342db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:31:03.710841Z",
     "iopub.status.busy": "2023-11-22T09:31:03.710629Z",
     "iopub.status.idle": "2023-11-22T09:33:18.730940Z",
     "shell.execute_reply": "2023-11-22T09:33:18.730158Z"
    },
    "papermill": {
     "duration": 135.107164,
     "end_time": "2023-11-22T09:33:18.733981",
     "exception": false,
     "start_time": "2023-11-22T09:31:03.626817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import datasets\n",
    "import transformers\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b3abce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:18.840277Z",
     "iopub.status.busy": "2023-11-22T09:33:18.839483Z",
     "iopub.status.idle": "2023-11-22T09:33:18.844736Z",
     "shell.execute_reply": "2023-11-22T09:33:18.844155Z"
    },
    "papermill": {
     "duration": 0.083224,
     "end_time": "2023-11-22T09:33:18.845960",
     "exception": false,
     "start_time": "2023-11-22T09:33:18.762736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !watch -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6579d707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:19.028925Z",
     "iopub.status.busy": "2023-11-22T09:33:19.028653Z",
     "iopub.status.idle": "2023-11-22T09:33:19.330107Z",
     "shell.execute_reply": "2023-11-22T09:33:19.329461Z"
    },
    "papermill": {
     "duration": 0.410757,
     "end_time": "2023-11-22T09:33:19.331428",
     "exception": false,
     "start_time": "2023-11-22T09:33:18.920671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1+cu117\n",
      "CUDA version: 11.7\n",
      "cuDNN version: 8500\n",
      "Current device: 0\n",
      "Is cuda available: True\n"
     ]
    }
   ],
   "source": [
    "print(f'PyTorch version: {torch.__version__}')  # 1.9.1+cu111\n",
    "print(f'CUDA version: {torch.version.cuda}')  # 11.1\n",
    "print(f'cuDNN version: {torch.backends.cudnn.version()}')  # 8005\n",
    "print(f'Current device: {torch.cuda.current_device()}')  # 0\n",
    "print(f'Is cuda available: {torch.cuda.is_available()}')  # TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30504d49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:19.502178Z",
     "iopub.status.busy": "2023-11-22T09:33:19.501844Z",
     "iopub.status.idle": "2023-11-22T09:33:19.516658Z",
     "shell.execute_reply": "2023-11-22T09:33:19.516210Z"
    },
    "papermill": {
     "duration": 0.107618,
     "end_time": "2023-11-22T09:33:19.517677",
     "exception": false,
     "start_time": "2023-11-22T09:33:19.410059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.32.1\n",
      "Datasets version: 2.14.4\n"
     ]
    }
   ],
   "source": [
    "print(f'Transformers version: {transformers.__version__}')\n",
    "print(f'Datasets version: {datasets.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f96c096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:19.666721Z",
     "iopub.status.busy": "2023-11-22T09:33:19.666510Z",
     "iopub.status.idle": "2023-11-22T09:33:19.679030Z",
     "shell.execute_reply": "2023-11-22T09:33:19.678625Z"
    },
    "papermill": {
     "duration": 0.097458,
     "end_time": "2023-11-22T09:33:19.680183",
     "exception": false,
     "start_time": "2023-11-22T09:33:19.582725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prevent a warning related to the tokenization process in the transformers library. \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "# Makes CUDA operations synchronous\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855ee0e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:19.849387Z",
     "iopub.status.busy": "2023-11-22T09:33:19.849167Z",
     "iopub.status.idle": "2023-11-22T09:33:20.295741Z",
     "shell.execute_reply": "2023-11-22T09:33:20.282928Z"
    },
    "papermill": {
     "duration": 0.545468,
     "end_time": "2023-11-22T09:33:20.305904",
     "exception": false,
     "start_time": "2023-11-22T09:33:19.760436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 22 10:33:20 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti      On | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 32%   56C    P2              254W / 250W|   7973MiB / 11264MiB |     85%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti      On | 00000000:23:00.0 Off |                  N/A |\r\n",
      "| 26%   49C    P2              168W / 250W|   7493MiB / 11264MiB |     35%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti      On | 00000000:41:00.0 Off |                  N/A |\r\n",
      "| 25%   46C    P2              126W / 250W|  11007MiB / 11264MiB |     36%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti      On | 00000000:61:00.0 Off |                  N/A |\r\n",
      "| 22%   31C    P2               61W / 250W|   9907MiB / 11264MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti      On | 00000000:81:00.0 Off |                  N/A |\r\n",
      "| 24%   45C    P2              121W / 250W|   8401MiB / 11264MiB |     29%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   5  NVIDIA GeForce RTX 2080 Ti      On | 00000000:A1:00.0 Off |                  N/A |\r\n",
      "| 25%   46C    P2              128W / 250W|   8321MiB / 11264MiB |     32%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti      On | 00000000:C1:00.0 Off |                  N/A |\r\n",
      "| 27%   47C    P2              140W / 250W|  10547MiB / 11264MiB |     40%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti      On | 00000000:E1:00.0 Off |                  N/A |\r\n",
      "|ERR!   37C    P2              ERR! / 250W|   7319MiB / 11264MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A   3241666      C   julia                                       242MiB |\r\n",
      "|    0   N/A  N/A   3386163      C   .../3.9.6-GCCcore-11.2.0/bin/python3.9     7726MiB |\r\n",
      "|    1   N/A  N/A    179880      C   python                                     7488MiB |\r\n",
      "|    2   N/A  N/A    179880      C   python                                     5168MiB |\r\n",
      "|    2   N/A  N/A    223694      C   python3                                     460MiB |\r\n",
      "|    2   N/A  N/A   4015618      C   python                                     5374MiB |\r\n",
      "|    3   N/A  N/A   2144696      C   ...arths/.conda/envs/codetf/bin/python     1058MiB |\r\n",
      "|    3   N/A  N/A   4015558      C   python                                     8424MiB |\r\n",
      "|    4   N/A  N/A    179880      C   python                                     7314MiB |\r\n",
      "|    4   N/A  N/A   2144696      C   ...arths/.conda/envs/codetf/bin/python     1082MiB |\r\n",
      "|    5   N/A  N/A    179880      C   python                                     7314MiB |\r\n",
      "|    5   N/A  N/A   2144696      C   ...arths/.conda/envs/codetf/bin/python     1002MiB |\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    6   N/A  N/A    179880      C   python                                     5168MiB |\r\n",
      "|    6   N/A  N/A   2140264      C   python                                     1336MiB |\r\n",
      "|    6   N/A  N/A   4012871      C   python                                     4038MiB |\r\n",
      "|    7   N/A  N/A    179880      C   python                                     7314MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# Find the GPU with the least memory usage.\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c72ee9e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:20.476937Z",
     "iopub.status.busy": "2023-11-22T09:33:20.476725Z",
     "iopub.status.idle": "2023-11-22T09:33:21.124063Z",
     "shell.execute_reply": "2023-11-22T09:33:21.105871Z"
    },
    "papermill": {
     "duration": 0.744449,
     "end_time": "2023-11-22T09:33:21.131530",
     "exception": false,
     "start_time": "2023-11-22T09:33:20.387081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 87% | 71% |\n",
      "|  1 | 35% | 67% |\n",
      "|  2 | 36% | 98% |\n",
      "|  3 |  0% | 88% |\n",
      "|  4 | 32% | 75% |\n",
      "|  5 | 29% | 74% |\n",
      "|  6 | 40% | 94% |\n",
      "|  7 |  0% | 65% |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 87% | 72% |\n",
      "|  1 | 34% | 67% |\n",
      "|  2 | 31% | 98% |\n",
      "|  3 |  0% | 88% |\n",
      "|  4 | 32% | 75% |\n",
      "|  5 | 29% | 74% |\n",
      "|  6 | 40% | 94% |\n",
      "|  7 |  0% | 65% |\n"
     ]
    }
   ],
   "source": [
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    # free unreferenced tensors from the GPU memory.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc89bc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:21.313723Z",
     "iopub.status.busy": "2023-11-22T09:33:21.313391Z",
     "iopub.status.idle": "2023-11-22T09:33:28.092002Z",
     "shell.execute_reply": "2023-11-22T09:33:28.071585Z"
    },
    "papermill": {
     "duration": 6.861649,
     "end_time": "2023-11-22T09:33:28.099459",
     "exception": false,
     "start_time": "2023-11-22T09:33:21.237810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the game is based on escape mechanics and need...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for example a core module should be contained ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this was done for one plugin in httpsgithubcom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>describe the bug the bot is throwing profane w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ability to transition from one state to another</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269572</th>\n",
       "      <td>when you run the trial it will set areas on fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269573</th>\n",
       "      <td>the navigator of the wiki should be edited and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269574</th>\n",
       "      <td>javascript code or see if possible without tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269575</th>\n",
       "      <td>we should document what exactly the sample is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269576</th>\n",
       "      <td>that can be opened from a dropdown menu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>269577 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean  label\n",
       "0       the game is based on escape mechanics and need...      0\n",
       "1       for example a core module should be contained ...      0\n",
       "2       this was done for one plugin in httpsgithubcom...      0\n",
       "3       describe the bug the bot is throwing profane w...      0\n",
       "4         ability to transition from one state to another      0\n",
       "...                                                   ...    ...\n",
       "269572  when you run the trial it will set areas on fi...      1\n",
       "269573  the navigator of the wiki should be edited and...      1\n",
       "269574  javascript code or see if possible without tha...      1\n",
       "269575  we should document what exactly the sample is ...      1\n",
       "269576            that can be opened from a dropdown menu      1\n",
       "\n",
       "[269577 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"csv/priority_high_low_clean.csv\" , index_col = 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f26fa5fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:28.274392Z",
     "iopub.status.busy": "2023-11-22T09:33:28.274104Z",
     "iopub.status.idle": "2023-11-22T09:33:28.287108Z",
     "shell.execute_reply": "2023-11-22T09:33:28.286489Z"
    },
    "papermill": {
     "duration": 0.091961,
     "end_time": "2023-11-22T09:33:28.288196",
     "exception": false,
     "start_time": "2023-11-22T09:33:28.196235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Smaller and faster than bert.\n",
    "base_model_id = \"distilbert-base-uncased\"\n",
    "\n",
    "epochs = 5 #Number of full cyles through the training set.\n",
    "num_labels = 2 #Number of labels, high, med, low priority.\n",
    "learning_rate = 5e-5 # Rate the model updates based on the data its trained on.\n",
    "train_batch_size = 16 # Number of training examples in one iteration.\n",
    "eval_batch_size = 32 # Number evalutaion examples in on iteratoion.\n",
    "save_strategy = \"no\" # Should the model be saved automatically during training.\n",
    "save_steps = 500 # How often to save the model during training. No effect since no over.\n",
    "logging_steps = 100\n",
    "model_dir = \"./model\" #Where to save model\n",
    "\n",
    "# Use early stopping to prevent overfitting\n",
    "#load_best_model_at_end=True\n",
    "#metric_for_best_model=\"eval_loss\"\n",
    "#greater_is_better=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c48ccefc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:28.432147Z",
     "iopub.status.busy": "2023-11-22T09:33:28.431820Z",
     "iopub.status.idle": "2023-11-22T09:33:28.444204Z",
     "shell.execute_reply": "2023-11-22T09:33:28.443443Z"
    },
    "papermill": {
     "duration": 0.097111,
     "end_time": "2023-11-22T09:33:28.451854",
     "exception": false,
     "start_time": "2023-11-22T09:33:28.354743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split dataframe into three parts: training, validation and testing.\n",
    "def train_validate_test_split(df, train_percent=.8, validate_percent=.1, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    # Shuffle index of dataframe\n",
    "    perm = np.random.permutation(df.index)\n",
    "    \n",
    "    df_length = len(df.index)\n",
    "    \n",
    "    # Number of row in training set\n",
    "    train_end = int(train_percent * df_length)\n",
    "    # Number of rows in validate set\n",
    "    validate_end = int(validate_percent * df_length) + train_end\n",
    "    \n",
    "    # From start to train end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    # From train_end to validate_end\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    # From validate to the last row in dataframe.\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "830cb234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:28.630868Z",
     "iopub.status.busy": "2023-11-22T09:33:28.630558Z",
     "iopub.status.idle": "2023-11-22T09:33:28.756155Z",
     "shell.execute_reply": "2023-11-22T09:33:28.742874Z"
    },
    "papermill": {
     "duration": 0.215949,
     "end_time": "2023-11-22T09:33:28.762902",
     "exception": false,
     "start_time": "2023-11-22T09:33:28.546953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drops rows with missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "365a025e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:28.921397Z",
     "iopub.status.busy": "2023-11-22T09:33:28.920782Z",
     "iopub.status.idle": "2023-11-22T09:33:28.943020Z",
     "shell.execute_reply": "2023-11-22T09:33:28.941479Z"
    },
    "papermill": {
     "duration": 0.122516,
     "end_time": "2023-11-22T09:33:28.950039",
     "exception": false,
     "start_time": "2023-11-22T09:33:28.827523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the game is based on escape mechanics and need...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>for example a core module should be contained ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>this was done for one plugin in httpsgithubcom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>describe the bug the bot is throwing profane w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ability to transition from one state to another</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269572</th>\n",
       "      <td>269572</td>\n",
       "      <td>when you run the trial it will set areas on fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269573</th>\n",
       "      <td>269573</td>\n",
       "      <td>the navigator of the wiki should be edited and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269574</th>\n",
       "      <td>269574</td>\n",
       "      <td>javascript code or see if possible without tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269575</th>\n",
       "      <td>269575</td>\n",
       "      <td>we should document what exactly the sample is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269576</th>\n",
       "      <td>269576</td>\n",
       "      <td>that can be opened from a dropdown menu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>269577 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                         text_clean  label\n",
       "0            0  the game is based on escape mechanics and need...      0\n",
       "1            1  for example a core module should be contained ...      0\n",
       "2            2  this was done for one plugin in httpsgithubcom...      0\n",
       "3            3  describe the bug the bot is throwing profane w...      0\n",
       "4            4    ability to transition from one state to another      0\n",
       "...        ...                                                ...    ...\n",
       "269572  269572  when you run the trial it will set areas on fi...      1\n",
       "269573  269573  the navigator of the wiki should be edited and...      1\n",
       "269574  269574  javascript code or see if possible without tha...      1\n",
       "269575  269575  we should document what exactly the sample is ...      1\n",
       "269576  269576            that can be opened from a dropdown menu      1\n",
       "\n",
       "[269577 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resets the index after dropping rows\n",
    "data.reset_index(inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29193757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:29.083625Z",
     "iopub.status.busy": "2023-11-22T09:33:29.083398Z",
     "iopub.status.idle": "2023-11-22T09:33:29.148160Z",
     "shell.execute_reply": "2023-11-22T09:33:29.134925Z"
    },
    "papermill": {
     "duration": 0.142331,
     "end_time": "2023-11-22T09:33:29.149860",
     "exception": false,
     "start_time": "2023-11-22T09:33:29.007529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Drops the index col, better for managint the data.\n",
    "data.drop(columns= [\"index\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d65133a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:29.335931Z",
     "iopub.status.busy": "2023-11-22T09:33:29.335593Z",
     "iopub.status.idle": "2023-11-22T09:33:29.361163Z",
     "shell.execute_reply": "2023-11-22T09:33:29.360505Z"
    },
    "papermill": {
     "duration": 0.124053,
     "end_time": "2023-11-22T09:33:29.363737",
     "exception": false,
     "start_time": "2023-11-22T09:33:29.239684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the game is based on escape mechanics and need...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for example a core module should be contained ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this was done for one plugin in httpsgithubcom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>describe the bug the bot is throwing profane w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ability to transition from one state to another</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269572</th>\n",
       "      <td>when you run the trial it will set areas on fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269573</th>\n",
       "      <td>the navigator of the wiki should be edited and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269574</th>\n",
       "      <td>javascript code or see if possible without tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269575</th>\n",
       "      <td>we should document what exactly the sample is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269576</th>\n",
       "      <td>that can be opened from a dropdown menu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>269577 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean  label\n",
       "0       the game is based on escape mechanics and need...      0\n",
       "1       for example a core module should be contained ...      0\n",
       "2       this was done for one plugin in httpsgithubcom...      0\n",
       "3       describe the bug the bot is throwing profane w...      0\n",
       "4         ability to transition from one state to another      0\n",
       "...                                                   ...    ...\n",
       "269572  when you run the trial it will set areas on fi...      1\n",
       "269573  the navigator of the wiki should be edited and...      1\n",
       "269574  javascript code or see if possible without tha...      1\n",
       "269575  we should document what exactly the sample is ...      1\n",
       "269576            that can be opened from a dropdown menu      1\n",
       "\n",
       "[269577 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb0e425f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:29.536455Z",
     "iopub.status.busy": "2023-11-22T09:33:29.536155Z",
     "iopub.status.idle": "2023-11-22T09:33:29.622495Z",
     "shell.execute_reply": "2023-11-22T09:33:29.610156Z"
    },
    "papermill": {
     "duration": 0.181822,
     "end_time": "2023-11-22T09:33:29.624321",
     "exception": false,
     "start_time": "2023-11-22T09:33:29.442499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 60% trainig, 20% validate, 20% test. Seed None.\n",
    "# Test 80-10-10 and 70-15-15\n",
    "train , validate , test = train_validate_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "024bdd28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:29.817253Z",
     "iopub.status.busy": "2023-11-22T09:33:29.816988Z",
     "iopub.status.idle": "2023-11-22T09:33:29.828361Z",
     "shell.execute_reply": "2023-11-22T09:33:29.827731Z"
    },
    "papermill": {
     "duration": 0.105616,
     "end_time": "2023-11-22T09:33:29.830482",
     "exception": false,
     "start_time": "2023-11-22T09:33:29.724866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.set_index(\"label\" , inplace = True)\n",
    "validate.set_index(\"label\" , inplace = True)\n",
    "test.set_index(\"label\" , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cb16842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:29.995797Z",
     "iopub.status.busy": "2023-11-22T09:33:29.995304Z",
     "iopub.status.idle": "2023-11-22T09:33:30.019260Z",
     "shell.execute_reply": "2023-11-22T09:33:30.018786Z"
    },
    "papermill": {
     "duration": 0.119507,
     "end_time": "2023-11-22T09:33:30.020324",
     "exception": false,
     "start_time": "2023-11-22T09:33:29.900817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>description even though we define a native fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i wanted to convert a vim user to spacemacs bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tasklist tasks httpsgithubcomensoorgensoissues...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is what the hosted world user sees in his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentry issue api4ahttpssentryioorganizationsno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i like this plugin really much and it is worki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well not a critical bug but if i press on dona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>epic story task epic 맵 화면 story 사용자가 방탈출 카페를 검...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>describe the bug the peripheral hr sample prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kinddocumentation im trying out odo with opens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26959 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_clean\n",
       "label                                                   \n",
       "1      description even though we define a native fun...\n",
       "0      i wanted to convert a vim user to spacemacs bu...\n",
       "0      tasklist tasks httpsgithubcomensoorgensoissues...\n",
       "0      this is what the hosted world user sees in his...\n",
       "0      sentry issue api4ahttpssentryioorganizationsno...\n",
       "...                                                  ...\n",
       "0      i like this plugin really much and it is worki...\n",
       "1      well not a critical bug but if i press on dona...\n",
       "0      epic story task epic 맵 화면 story 사용자가 방탈출 카페를 검...\n",
       "1      describe the bug the peripheral hr sample prog...\n",
       "0      kinddocumentation im trying out odo with opens...\n",
       "\n",
       "[26959 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a32ee5b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:30.242610Z",
     "iopub.status.busy": "2023-11-22T09:33:30.242344Z",
     "iopub.status.idle": "2023-11-22T09:33:30.639819Z",
     "shell.execute_reply": "2023-11-22T09:33:30.639292Z"
    },
    "papermill": {
     "duration": 0.483869,
     "end_time": "2023-11-22T09:33:30.643625",
     "exception": false,
     "start_time": "2023-11-22T09:33:30.159756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 26959\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 215661\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 26957\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert from Pandas DataFrame to Hugging Face datasets\n",
    "tds = Dataset.from_pandas(train)\n",
    "vds = Dataset.from_pandas(validate)\n",
    "testds = Dataset.from_pandas(test)\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds[\"test\"] = testds\n",
    "ds[\"train\"] = tds\n",
    "ds[\"validate\"] = vds\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "386b14ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:30.785831Z",
     "iopub.status.busy": "2023-11-22T09:33:30.785599Z",
     "iopub.status.idle": "2023-11-22T09:33:30.795636Z",
     "shell.execute_reply": "2023-11-22T09:33:30.795235Z"
    },
    "papermill": {
     "duration": 0.084923,
     "end_time": "2023-11-22T09:33:30.796847",
     "exception": false,
     "start_time": "2023-11-22T09:33:30.711924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = ds[\"train\"]\n",
    "valid_dataset = ds[\"validate\"]\n",
    "test_ds = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3263a36c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:30.970279Z",
     "iopub.status.busy": "2023-11-22T09:33:30.970040Z",
     "iopub.status.idle": "2023-11-22T09:33:31.008678Z",
     "shell.execute_reply": "2023-11-22T09:33:31.008258Z"
    },
    "papermill": {
     "duration": 0.145141,
     "end_time": "2023-11-22T09:33:31.020887",
     "exception": false,
     "start_time": "2023-11-22T09:33:30.875746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_clean': 'to be more inclusive of hsdm would ideally add the hms and hsdm crests logos will reach out to communications office for clearance',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7ef1614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:31.194552Z",
     "iopub.status.busy": "2023-11-22T09:33:31.194287Z",
     "iopub.status.idle": "2023-11-22T09:33:31.199371Z",
     "shell.execute_reply": "2023-11-22T09:33:31.198975Z"
    },
    "papermill": {
     "duration": 0.083288,
     "end_time": "2023-11-22T09:33:31.200634",
     "exception": false,
     "start_time": "2023-11-22T09:33:31.117346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbffc393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:31.381450Z",
     "iopub.status.busy": "2023-11-22T09:33:31.381216Z",
     "iopub.status.idle": "2023-11-22T09:33:38.854937Z",
     "shell.execute_reply": "2023-11-22T09:33:38.841070Z"
    },
    "papermill": {
     "duration": 7.579734,
     "end_time": "2023-11-22T09:33:38.859184",
     "exception": false,
     "start_time": "2023-11-22T09:33:31.279450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_id, num_labels=num_labels)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "# optim = torch.optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484feadf",
   "metadata": {
    "papermill": {
     "duration": 0.103972,
     "end_time": "2023-11-22T09:33:39.044638",
     "exception": false,
     "start_time": "2023-11-22T09:33:38.940666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d90b52d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:39.221707Z",
     "iopub.status.busy": "2023-11-22T09:33:39.221388Z",
     "iopub.status.idle": "2023-11-22T09:33:39.967395Z",
     "shell.execute_reply": "2023-11-22T09:33:39.966592Z"
    },
    "papermill": {
     "duration": 0.829668,
     "end_time": "2023-11-22T09:33:39.969201",
     "exception": false,
     "start_time": "2023-11-22T09:33:39.139533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76dfffd",
   "metadata": {
    "papermill": {
     "duration": 0.096554,
     "end_time": "2023-11-22T09:33:40.146068",
     "exception": false,
     "start_time": "2023-11-22T09:33:40.049514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "    Tokenizing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c848144",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:33:40.306908Z",
     "iopub.status.busy": "2023-11-22T09:33:40.306650Z",
     "iopub.status.idle": "2023-11-22T09:38:03.307711Z",
     "shell.execute_reply": "2023-11-22T09:38:03.307238Z"
    },
    "papermill": {
     "duration": 263.093207,
     "end_time": "2023-11-22T09:38:03.308859",
     "exception": false,
     "start_time": "2023-11-22T09:33:40.215652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f877d1977f404ee4b2bf2cbf29caa0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/215661 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b84435d487471397027748162d0ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26957 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8490707e516f45b888cb1b66167a4b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26959 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenize the dataset to the correct input for the transformer model.\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text_clean\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "valid_dataset = valid_dataset.map(tokenize, batched=True, batch_size=len(valid_dataset))\n",
    "test_dataset = test_ds.map(tokenize, batched=True, batch_size=len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10c7769",
   "metadata": {
    "papermill": {
     "duration": 0.094981,
     "end_time": "2023-11-22T09:38:03.492957",
     "exception": false,
     "start_time": "2023-11-22T09:38:03.397976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a5a7f8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:38:03.695115Z",
     "iopub.status.busy": "2023-11-22T09:38:03.694876Z",
     "iopub.status.idle": "2023-11-22T09:38:03.782286Z",
     "shell.execute_reply": "2023-11-22T09:38:03.781894Z"
    },
    "papermill": {
     "duration": 0.192188,
     "end_time": "2023-11-22T09:38:03.783554",
     "exception": false,
     "start_time": "2023-11-22T09:38:03.591366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    save_strategy=save_strategy,\n",
    "    save_steps=save_steps,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "318fc8a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:38:03.963322Z",
     "iopub.status.busy": "2023-11-22T09:38:03.963171Z",
     "iopub.status.idle": "2023-11-22T09:38:15.324157Z",
     "shell.execute_reply": "2023-11-22T09:38:15.316569Z"
    },
    "papermill": {
     "duration": 11.433197,
     "end_time": "2023-11-22T09:38:15.326129",
     "exception": false,
     "start_time": "2023-11-22T09:38:03.892932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b5578f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:38:15.517419Z",
     "iopub.status.busy": "2023-11-22T09:38:15.517086Z"
    },
    "papermill": {
     "duration": 2604.462848,
     "end_time": "2023-11-22T10:21:39.906849",
     "exception": false,
     "start_time": "2023-11-22T09:38:15.444001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac7267",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Training loss: Difference between the predictons made by the model on the training dataset vs on the actual data.\n",
    "* Validation loss: how well the model functions on unseen data.\n",
    "* Accuracy: How much the model gets correct. number of correct Prediction / total number of predictions.\n",
    "* F1: consider both precision and recall. \n",
    "* Precision: Accuracy of positive predictions. Percison TP = TP + FP. How often the model is correct.\n",
    "* Recall: True positive rate. how many items the model gets correct from the total amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c34a7fd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training loss decreases, valdiation loss increases = Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a791423d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate valdiation set\n",
    "eval_result = trainer.evaluate(eval_dataset=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88295878",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, value in sorted(eval_result.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce22454",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate test data set\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970cfc5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, value in sorted(test_results.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c8395",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir + \"_local\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac76c94",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "    \n",
    "classifier = pipeline(\"text-classification\", model=\"./model_local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534615c2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee71c0f7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier(\"this does not need to be done fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978b8ee",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier(\"this is super important\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb83892",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier(\"this bug has super high impact on the project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a082ef",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Important to delete large objects to free memory \n",
    "del train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bc1927",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d547dc0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff22f3df",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Free cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2be48e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff4d6b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3062.463687,
   "end_time": "2023-11-22T10:21:45.626765",
   "environment_variables": {},
   "exception": null,
   "input_path": "04_bert_priority.ipynb",
   "output_path": "04_bert_priority_out.ipynb",
   "parameters": {},
   "start_time": "2023-11-22T09:30:43.163078",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}