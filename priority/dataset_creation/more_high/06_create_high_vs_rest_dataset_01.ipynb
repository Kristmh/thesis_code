{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_files = \"/fp/projects01/ec307/ec-krimhau/github_datasets\"\n",
    "file_name = \"clean_github_repos_with_priority_issues.csv\"\n",
    "full_path = f'{path_to_files}/{file_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "df = pd.read_csv(f'{path_to_files}/{file_name}')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicate issues. \n",
    "df = df.drop_duplicates(subset='text')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_repos = ['AdguardTeam/AdguardFilters']\n",
    "df = df[~df['repo'].isin(bad_repos)]\n",
    "# Drop missing values from df\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Reset the index of df\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p2\n",
    "df.loc[df[\"class\"] == \"p2\", 'labels'].value_counts().to_frame().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical value count\n",
    "df.loc[df['class'] == 'critical', 'labels'].value_counts().to_frame().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top labels for each priority level\n",
    "df.loc[df['class'] == 'high', 'labels'].value_counts().to_frame().head(50)\n",
    "# Print all labels for high priority\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#df.loc[df['class'] == 'High', 'labels'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medium\n",
    "df.loc[df['class'] == 'medium', 'labels'].value_counts().to_frame().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low\n",
    "df.loc[df['class'] == 'low', 'labels'].value_counts().to_frame().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_priority\n",
    "df.loc[df['class'] == 'non_priority', 'labels'].value_counts().to_frame().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_triage\n",
    "df.loc[df['class'] == 'in_triage', 'labels'].value_counts().to_frame().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique repo\n",
    "df['repo'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of issues per repo\n",
    "df['repo'].value_counts().to_frame()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value count labels\n",
    "df[\"labels\"].value_counts().to_frame()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('class').to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = df[df['class'] == 'high']\n",
    "high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical = df[df['class'] == 'critical']\n",
    "critical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_high = df[df['class'] == 'p2_high']\n",
    "p2_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = df[df['class'] == 'low']\n",
    "low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium = df[df['class'] == 'medium']\n",
    "medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_priority = df[df['class'] == 'non_priority']\n",
    "non_priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_priority = pd.concat([critical, high, p2_high], ignore_index=True)\n",
    "high_priority[\"label\"] = 1\n",
    "high_priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = pd.concat([non_priority, low, medium], ignore_index=True)\n",
    "rest[\"label\"] = 0\n",
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "# Number of rows in the highest class\n",
    "n_high = high_priority.shape[0]\n",
    "\n",
    "rest_sampled = rest.sample(n=n_high, random_state=42)  \n",
    "\n",
    "\n",
    "balanced_data = pd.concat([high_priority, rest_sampled])\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "balanced_data = shuffle(balanced_data, random_state=42)\n",
    "balanced_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data = balanced_data[[\"label\", \"text\"]]\n",
    "balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data.to_csv(f'{path_to_files}/HP_vs_rest/high_vs_rest_balanced_github.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
