{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f89275a9",
   "metadata": {},
   "source": [
    "# Importsand preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d342db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itf-fi-ml/home/krimhau/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import datasets\n",
    "import transformers\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b3abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !watch -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6579d707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0+cu121\n",
      "CUDA version: 12.1\n",
      "cuDNN version: 8902\n",
      "Current device: 0\n",
      "Is cuda available: True\n"
     ]
    }
   ],
   "source": [
    "print(f'PyTorch version: {torch.__version__}')  # 1.9.1+cu111\n",
    "print(f'CUDA version: {torch.version.cuda}')  # 11.1\n",
    "print(f'cuDNN version: {torch.backends.cudnn.version()}')  # 8005\n",
    "print(f'Current device: {torch.cuda.current_device()}')  # 0\n",
    "print(f'Is cuda available: {torch.cuda.is_available()}')  # TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30504d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.35.0\n",
      "Datasets version: 2.14.6\n"
     ]
    }
   ],
   "source": [
    "print(f'Transformers version: {transformers.__version__}')\n",
    "print(f'Datasets version: {datasets.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f96c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent a warning related to the tokenization process in the transformers library. \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "# Makes CUDA operations synchronous\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855ee0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 27 09:50:27 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8              12W / 250W |  10503MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:23:00.0 Off |                  N/A |\n",
      "| 34%   57C    P2             249W / 250W |   8747MiB / 11264MiB |     97%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 28%   49C    P2             137W / 250W |   8111MiB / 11264MiB |     51%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:61:00.0 Off |                  N/A |\n",
      "| 22%   24C    P8              17W / 250W |  10503MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:81:00.0 Off |                  N/A |\n",
      "| 34%   58C    P2             232W / 250W |   8439MiB / 11264MiB |     97%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8              18W / 250W |  10157MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 28%   48C    P2             136W / 250W |   8103MiB / 11264MiB |     51%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 22%   24C    P8              18W / 250W |      3MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    257091      C   python                                    10500MiB |\n",
      "|    1   N/A  N/A    387032      C   ...dinger/2023-3/internal/bin/gdesmond      336MiB |\n",
      "|    1   N/A  N/A    965029      C   python                                     8100MiB |\n",
      "|    1   N/A  N/A   3864033      C   python                                      308MiB |\n",
      "|    2   N/A  N/A    965029      C   python                                     8108MiB |\n",
      "|    3   N/A  N/A   3986009      C   python                                    10500MiB |\n",
      "|    4   N/A  N/A    916400      C   ...dinger/2023-3/internal/bin/gdesmond      368MiB |\n",
      "|    4   N/A  N/A    965029      C   python                                     8100MiB |\n",
      "|    5   N/A  N/A    124769      C   ...me/karths/.conda/envs/dl/bin/python     4882MiB |\n",
      "|    5   N/A  N/A    579445      C   ...me/karths/.conda/envs/dl/bin/python     5272MiB |\n",
      "|    6   N/A  N/A    965029      C   python                                     8100MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Find the GPU with the least memory usage.\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c72ee9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 93% |\n",
      "|  1 | 97% | 78% |\n",
      "|  2 | 50% | 72% |\n",
      "|  3 |  0% | 93% |\n",
      "|  4 | 97% | 75% |\n",
      "|  5 |  0% | 90% |\n",
      "|  6 | 51% | 72% |\n",
      "|  7 |  0% |  0% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 93% |\n",
      "|  1 | 97% | 78% |\n",
      "|  2 | 50% | 72% |\n",
      "|  3 |  0% | 93% |\n",
      "|  4 | 93% | 75% |\n",
      "|  5 |  0% | 90% |\n",
      "|  6 | 49% | 72% |\n",
      "|  7 |  0% |  1% |\n"
     ]
    }
   ],
   "source": [
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    # free unreferenced tensors from the GPU memory.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f26fa5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller and faster than bert.\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "\n",
    "epochs = 5 #Number of full cycles through the training set.\n",
    "num_labels = 2 #Number of labels, high, med, low priority.\n",
    "learning_rate = 5e-5 # Rate the model updates based on the data its trained on.\n",
    "train_batch_size = 16 # Number of training examples in one iteration.\n",
    "eval_batch_size = 32 # Number evaluation examples in on iteration.\n",
    "save_strategy = \"no\" # Should the model be saved automatically during training.\n",
    "save_steps = 500 # How often to save the model during training. No effect since no over.\n",
    "logging_steps = 100\n",
    "model_dir = \"./model\" #Where to save model\n",
    "\n",
    "# Use early stopping to prevent overfitting\n",
    "#load_best_model_at_end=True\n",
    "#metric_for_best_model=\"eval_loss\"\n",
    "#greater_is_better=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efee485",
   "metadata": {},
   "source": [
    "Load dataset from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f2d5625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'text_clean', 'label', '__index_level_0__'],\n",
       "        num_rows: 11681\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'text_clean', 'label', '__index_level_0__'],\n",
       "        num_rows: 93441\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['Unnamed: 0', 'text_clean', 'label', '__index_level_0__'],\n",
       "        num_rows: 11680\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"kristmh/high_vs_randommin_100_issues_per_repo\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91a279d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 476/476 [00:00<00:00, 2.32MB/s]\n",
      "Downloading data files:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|                                                                                                                                              | 0.00/1.58M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.58M/1.58M [00:00<00:00, 3.11MB/s]\u001b[A\n",
      "Downloading data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 326.08it/s]\n",
      "Generating test split: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1570/1570 [00:00<00:00, 11921.03 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 1570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rust = load_dataset(\"kristmh/rust_testset\")\n",
    "rust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d41ea58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 479/479 [00:00<00:00, 3.56MB/s]\n",
      "Downloading data files:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|                                                                                                                                              | 0.00/1.93M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.93M/1.93M [00:00<00:00, 5.53MB/s]\u001b[A\n",
      "Downloading data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 310.74it/s]\n",
      "Generating test split: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2374/2374 [00:00<00:00, 22795.03 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 2374\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flutter = load_dataset(\"kristmh/flutter_testset\")\n",
    "flutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0c8b1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 472/472 [00:00<00:00, 3.55MB/s]\n",
      "Downloading data files:   0%|                                                                                                                                              | 0/1 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|                                                                                                                                               | 0.00/394k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 394k/394k [00:00<00:00, 1.16MB/s]\u001b[A\n",
      "Downloading data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.80it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 429.61it/s]\n",
      "Generating test split: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 734/734 [00:00<00:00, 14409.57 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 734\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypy = load_dataset(\"kristmh/mypy_testset\")\n",
    "mypy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7ef1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "051c5a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbffc393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484feadf",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d90b52d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76dfffd",
   "metadata": {},
   "source": [
    "    Tokenizing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c848144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the dataset to the correct input for the transformer model.\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text_clean\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51843237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1570/1570 [00:04<00:00, 316.85 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text_clean', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1570\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rust_tokenized = rust.map(tokenize, batched=True)\n",
    "rust_testset = rust_tokenized[\"test\"]\n",
    "rust_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8db7d305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2374/2374 [00:05<00:00, 450.19 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text_clean', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 2374\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flutter_tokenized = flutter.map(tokenize, batched=True)\n",
    "flutter_testset = flutter_tokenized[\"test\"]\n",
    "flutter_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66ce7684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 734/734 [00:00<00:00, 819.45 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text_clean', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 734\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypy_tokenized = mypy.map(tokenize, batched=True)\n",
    "mypy_testset = mypy_tokenized[\"test\"]\n",
    "mypy_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a425bf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11681/11681 [00:12<00:00, 907.10 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'text_clean', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 11681\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'text_clean', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 93441\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['Unnamed: 0', 'text_clean', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 11680\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b50c5678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Unnamed: 0', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 93441\n",
      "})\n",
      "Dataset({\n",
      "    features: ['Unnamed: 0', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 11680\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 11681\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the columns of the dataset.\n",
    "# Should be: [\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"]\n",
    "# Remove unnecessary columns that the model does not expect.\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text_clean\", \"__index_level_0__\"])\n",
    "\n",
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "print(train_dataset)\n",
    "validation_dataset = tokenized_dataset[\"validate\"]\n",
    "print(validation_dataset)\n",
    "test_dataset = tokenized_dataset[\"test\"]\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10c7769",
   "metadata": {},
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a5a7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    save_strategy=save_strategy,\n",
    "    save_steps=save_steps,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "318fc8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b5578f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29205' max='29205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29205/29205 2:30:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.588200</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.695462</td>\n",
       "      <td>[0.69914573 0.69168761]</td>\n",
       "      <td>[0.68280192 0.70908122]</td>\n",
       "      <td>[0.71629116 0.6751269 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.573759</td>\n",
       "      <td>0.709932</td>\n",
       "      <td>[0.72156476 0.69728377]</td>\n",
       "      <td>[0.68615192 0.73873533]</td>\n",
       "      <td>[0.76083189 0.66023689]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.501800</td>\n",
       "      <td>0.567311</td>\n",
       "      <td>0.718836</td>\n",
       "      <td>[0.72855017 0.70839993]</td>\n",
       "      <td>[0.69642857 0.74532885]</td>\n",
       "      <td>[0.76377816 0.6749577 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.444500</td>\n",
       "      <td>0.629449</td>\n",
       "      <td>0.714127</td>\n",
       "      <td>[0.70464396 0.72301949]</td>\n",
       "      <td>[0.71960253 0.70919447]</td>\n",
       "      <td>[0.69029463 0.73739425]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.323500</td>\n",
       "      <td>0.690094</td>\n",
       "      <td>0.713442</td>\n",
       "      <td>[0.7159467  0.71089229]</td>\n",
       "      <td>[0.70148013 0.72613376]</td>\n",
       "      <td>[0.73102253 0.6962775 ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=29205, training_loss=0.47980963953593236, metrics={'train_runtime': 9038.9415, 'train_samples_per_second': 51.688, 'train_steps_per_second': 3.231, 'total_flos': 6.188943098907648e+16, 'train_loss': 0.47980963953593236, 'epoch': 5.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac7267",
   "metadata": {},
   "source": [
    "* Training loss: Difference between the predictons made by the model on the training dataset vs on the actual data.\n",
    "* Validation loss: how well the model functions on unseen data.\n",
    "* Accuracy: How much the model gets correct. number of correct Prediction / total number of predictions.\n",
    "* F1: consider both precision and recall. \n",
    "* Precision: Accuracy of positive predictions. Percison TP = TP + FP. How often the model is correct.\n",
    "* Recall: True positive rate. how many items the model gets correct from the total amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c34a7fd",
   "metadata": {},
   "source": [
    "### Training loss decreases, validation loss increases = Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a791423d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='879' max='365' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [365/365 02:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate validation set\n",
    "eval_result = trainer.evaluate(eval_dataset=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88295878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.7134417808219178\n",
      "\n",
      "eval_f1 = [0.7159467  0.71089229]\n",
      "\n",
      "eval_loss = 0.6900939345359802\n",
      "\n",
      "eval_precision = [0.70148013 0.72613376]\n",
      "\n",
      "eval_recall = [0.73102253 0.6962775 ]\n",
      "\n",
      "eval_runtime = 72.5706\n",
      "\n",
      "eval_samples_per_second = 160.947\n",
      "\n",
      "eval_steps_per_second = 5.03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(eval_result.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dce22454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data set\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5970cfc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.7154353223182947\n",
      "\n",
      "eval_f1 = [0.72118772 0.70944056]\n",
      "\n",
      "eval_loss = 0.6858648061752319\n",
      "\n",
      "eval_precision = [0.70707237 0.72451348]\n",
      "\n",
      "eval_recall = [0.73587812 0.69498202]\n",
      "\n",
      "eval_runtime = 72.6024\n",
      "\n",
      "eval_samples_per_second = 160.89\n",
      "\n",
      "eval_steps_per_second = 5.041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(test_results.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a470906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.567515923566879\n",
      "\n",
      "eval_f1 = [0.49889299 0.61960784]\n",
      "\n",
      "eval_loss = 1.130395770072937\n",
      "\n",
      "eval_precision = [0.59298246 0.553     ]\n",
      "\n",
      "eval_recall = [0.43057325 0.7044586 ]\n",
      "\n",
      "eval_runtime = 9.7685\n",
      "\n",
      "eval_samples_per_second = 160.721\n",
      "\n",
      "eval_steps_per_second = 5.119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rust_test_results = trainer.evaluate(eval_dataset=rust_testset)\n",
    "for key, value in sorted(rust_test_results.items()):\n",
    "    print(f\"{key} = {value}\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dad7abb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.5122156697556866\n",
      "\n",
      "eval_f1 = [0.20357634 0.64845173]\n",
      "\n",
      "eval_loss = 1.648248314857483\n",
      "\n",
      "eval_precision = [0.55430712 0.50688182]\n",
      "\n",
      "eval_recall = [0.12468408 0.89974726]\n",
      "\n",
      "eval_runtime = 14.7473\n",
      "\n",
      "eval_samples_per_second = 160.979\n",
      "\n",
      "eval_steps_per_second = 5.086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flutter_test_results = trainer.evaluate(eval_dataset=flutter_testset)\n",
    "for key, value in sorted(flutter_test_results.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc9ed549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.5871934604904632\n",
      "\n",
      "eval_f1 = [0.55243722 0.61694058]\n",
      "\n",
      "eval_loss = 1.024633765220642\n",
      "\n",
      "eval_precision = [0.60322581 0.5754717 ]\n",
      "\n",
      "eval_recall = [0.50953678 0.66485014]\n",
      "\n",
      "eval_runtime = 4.5637\n",
      "\n",
      "eval_samples_per_second = 160.834\n",
      "\n",
      "eval_steps_per_second = 5.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mypy_test_results = trainer.evaluate(eval_dataset=mypy_testset)\n",
    "for key, value in sorted(mypy_test_results.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1831e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir + \"_local\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cac76c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "    \n",
    "classifier = pipeline(\"text-classification\", model=\"./model_local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "534615c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee71c0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.5006888508796692}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this does not need to be done fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3978b8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.7700179815292358}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this is super important\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcb83892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.6867467761039734}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this bug has super high impact on the project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a082ef",
   "metadata": {},
   "source": [
    "## Important to delete large objects to free memory \n",
    "del train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44bc1927",
   "metadata": {},
   "outputs": [],
   "source": [
    "del validation_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d547dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff22f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f2be48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 27 12:24:44 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 22%   26C    P8              12W / 250W |  10503MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:23:00.0 Off |                  N/A |\n",
      "| 34%   58C    P2             237W / 250W |   8747MiB / 11264MiB |     97%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 28%   51C    P2             161W / 250W |   8111MiB / 11264MiB |     53%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:61:00.0 Off |                  N/A |\n",
      "| 22%   24C    P8              16W / 250W |  10503MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:81:00.0 Off |                  N/A |\n",
      "| 34%   57C    P2             224W / 250W |   8439MiB / 11264MiB |     98%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 22%   27C    P8              18W / 250W |  10157MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 29%   51C    P2             153W / 250W |   8103MiB / 11264MiB |     52%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti     On  | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 31%   48C    P2              67W / 250W |   1211MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    257091      C   python                                    10500MiB |\n",
      "|    1   N/A  N/A    387032      C   ...dinger/2023-3/internal/bin/gdesmond      336MiB |\n",
      "|    1   N/A  N/A    965029      C   python                                     8100MiB |\n",
      "|    1   N/A  N/A   3864033      C   python                                      308MiB |\n",
      "|    2   N/A  N/A    965029      C   python                                     8108MiB |\n",
      "|    3   N/A  N/A   3986009      C   python                                    10500MiB |\n",
      "|    4   N/A  N/A    916400      C   ...dinger/2023-3/internal/bin/gdesmond      336MiB |\n",
      "|    4   N/A  N/A    965029      C   python                                     8100MiB |\n",
      "|    5   N/A  N/A    124769      C   ...me/karths/.conda/envs/dl/bin/python     4882MiB |\n",
      "|    5   N/A  N/A    579445      C   ...me/karths/.conda/envs/dl/bin/python     5272MiB |\n",
      "|    6   N/A  N/A    965029      C   python                                     8100MiB |\n",
      "|    7   N/A  N/A   3955532      C   ...u/miniconda3/envs/thesis/bin/python     1208MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
