{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28e4448",
   "metadata": {},
   "source": [
    "# Importsand preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f405647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import datasets\n",
    "import transformers\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb9da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !watch -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0341a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1+cu117\n",
      "CUDA version: 11.7\n",
      "cuDNN version: 8500\n",
      "Current device: 0\n",
      "Is cuda available: True\n"
     ]
    }
   ],
   "source": [
    "print(f'PyTorch version: {torch.__version__}')  # 1.9.1+cu111\n",
    "print(f'CUDA version: {torch.version.cuda}')  # 11.1\n",
    "print(f'cuDNN version: {torch.backends.cudnn.version()}')  # 8005\n",
    "print(f'Current device: {torch.cuda.current_device()}')  # 0\n",
    "print(f'Is cuda available: {torch.cuda.is_available()}')  # TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420cadf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.32.1\n",
      "Datasets version: 2.14.4\n"
     ]
    }
   ],
   "source": [
    "print(f'Transformers version: {transformers.__version__}')\n",
    "print(f'Datasets version: {datasets.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36b5ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent a warning related to the tokenization process in the transformers library. \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "# Makes CUDA operations synchronous\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c96c170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 26 12:25:29 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti      On | 00000000:01:00.0 Off |                  N/A |\n",
      "| 23%   43C    P2               62W / 250W|    949MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti      On | 00000000:23:00.0 Off |                  N/A |\n",
      "| 42%   70C    P2              249W / 250W|   9213MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti      On | 00000000:41:00.0 Off |                  N/A |\n",
      "| 42%   70C    P2              248W / 250W|   9213MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti      On | 00000000:61:00.0 Off |                  N/A |\n",
      "| 36%   62C    P2              237W / 250W|   9213MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti      On | 00000000:81:00.0 Off |                  N/A |\n",
      "| 22%   39C    P2               49W / 250W|   1307MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti      On | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 22%   29C    P8               17W / 250W|      5MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti      On | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 22%   34C    P8               21W / 250W|      5MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti      On | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 38%   65C    P2              251W / 250W|   9213MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    1   N/A  N/A   2462076      C   ...ml/home/limeng/torch_env/bin/python     9206MiB |\n",
      "|    2   N/A  N/A   2462077      C   ...ml/home/limeng/torch_env/bin/python     9206MiB |\n",
      "|    3   N/A  N/A   2462078      C   ...ml/home/limeng/torch_env/bin/python     9206MiB |\n",
      "|    7   N/A  N/A   2462079      C   ...ml/home/limeng/torch_env/bin/python     9206MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Find the GPU with the least memory usage.\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01cf4459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 |   0% |  8% |\n",
      "|  1 | 100% | 82% |\n",
      "|  2 | 100% | 82% |\n",
      "|  3 | 100% | 82% |\n",
      "|  4 |   0% | 12% |\n",
      "|  5 |   0% |  0% |\n",
      "|  6 |   0% |  0% |\n",
      "|  7 | 100% | 82% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 |   0% |  8% |\n",
      "|  1 | 100% | 82% |\n",
      "|  2 | 100% | 82% |\n",
      "|  3 | 100% | 82% |\n",
      "|  4 |   0% | 12% |\n",
      "|  5 |   0% |  0% |\n",
      "|  6 |   1% |  1% |\n",
      "|  7 | 100% | 82% |\n"
     ]
    }
   ],
   "source": [
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    # free unreferenced tensors from the GPU memory.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cc384f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>create new vignette on project team grading wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app crashes when darryl visits messagesscreen ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>missing onrequeststart rolecheck dont always w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>describe the bug i noticed i now have the opti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>describe the bug h make hash 1 2 3 4 5 make ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112304</th>\n",
       "      <td>with alertlistings collections passed in to qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112305</th>\n",
       "      <td>for some reason the datetime in planner is not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112306</th>\n",
       "      <td>hi all i found some mistakes in our document s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112307</th>\n",
       "      <td>id 0x7b7d2f7b7d2f7b6578706f727465645f6e616d657...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112308</th>\n",
       "      <td>chefsale i believe you already work on this so...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112309 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean  label\n",
       "0       create new vignette on project team grading wi...      0\n",
       "1       app crashes when darryl visits messagesscreen ...      0\n",
       "2       missing onrequeststart rolecheck dont always w...      0\n",
       "3       describe the bug i noticed i now have the opti...      0\n",
       "4       describe the bug h make hash 1 2 3 4 5 make ha...      0\n",
       "...                                                   ...    ...\n",
       "112304  with alertlistings collections passed in to qu...      1\n",
       "112305  for some reason the datetime in planner is not...      1\n",
       "112306  hi all i found some mistakes in our document s...      1\n",
       "112307  id 0x7b7d2f7b7d2f7b6578706f727465645f6e616d657...      1\n",
       "112308  chefsale i believe you already work on this so...      1\n",
       "\n",
       "[112309 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"csv/priority_high_or_not_high_clean.csv\" , index_col = 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffe8ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller and farter than bert.\n",
    "base_model_id = \"distilbert-base-uncased\"\n",
    "\n",
    "epochs = 5 #Number of full cyles through the training set.\n",
    "num_labels = 2 #Number of labels, high, med, low priority.\n",
    "learning_rate = 5e-5 # Rate the model updates based on the data its trained on.\n",
    "train_batch_size = 16 # Number of training examples in one iteration.\n",
    "eval_batch_size = 32 # Number evalutaion examples in on iteratoion.\n",
    "save_strategy = \"no\" # Should the model be saved automatically during training.\n",
    "save_steps = 500 # How often to save the model during training. No effect since no over.\n",
    "logging_steps = 100\n",
    "model_dir = \"./model\" #Where to save model\n",
    "\n",
    "# Use early stopping to prevent overfitting\n",
    "#load_best_model_at_end=True\n",
    "#metric_for_best_model=\"eval_loss\"\n",
    "#greater_is_better=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1a0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split dataframe into three parts: training, validation and testing.\n",
    "def train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    # Shuffle index of dataframe\n",
    "    perm = np.random.permutation(df.index)\n",
    "    \n",
    "    df_length = len(df.index)\n",
    "    \n",
    "    # Number of row in training set\n",
    "    train_end = int(train_percent * df_length)\n",
    "    # Number of rows in validate set\n",
    "    validate_end = int(validate_percent * df_length) + train_end\n",
    "    \n",
    "    # From start to train end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    # From train_end to validate_end\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    # From validate to the last row in dataframe.\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a520691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops rows with missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aafad35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>create new vignette on project team grading wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>app crashes when darryl visits messagesscreen ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>missing onrequeststart rolecheck dont always w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>describe the bug i noticed i now have the opti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>describe the bug h make hash 1 2 3 4 5 make ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112304</th>\n",
       "      <td>112304</td>\n",
       "      <td>with alertlistings collections passed in to qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112305</th>\n",
       "      <td>112305</td>\n",
       "      <td>for some reason the datetime in planner is not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112306</th>\n",
       "      <td>112306</td>\n",
       "      <td>hi all i found some mistakes in our document s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112307</th>\n",
       "      <td>112307</td>\n",
       "      <td>id 0x7b7d2f7b7d2f7b6578706f727465645f6e616d657...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112308</th>\n",
       "      <td>112308</td>\n",
       "      <td>chefsale i believe you already work on this so...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112309 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                         text_clean  label\n",
       "0            0  create new vignette on project team grading wi...      0\n",
       "1            1  app crashes when darryl visits messagesscreen ...      0\n",
       "2            2  missing onrequeststart rolecheck dont always w...      0\n",
       "3            3  describe the bug i noticed i now have the opti...      0\n",
       "4            4  describe the bug h make hash 1 2 3 4 5 make ha...      0\n",
       "...        ...                                                ...    ...\n",
       "112304  112304  with alertlistings collections passed in to qu...      1\n",
       "112305  112305  for some reason the datetime in planner is not...      1\n",
       "112306  112306  hi all i found some mistakes in our document s...      1\n",
       "112307  112307  id 0x7b7d2f7b7d2f7b6578706f727465645f6e616d657...      1\n",
       "112308  112308  chefsale i believe you already work on this so...      1\n",
       "\n",
       "[112309 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resets the index after dropping rows\n",
    "data.reset_index(inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e76e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drops the index col, better for managint the data.\n",
    "data.drop(columns= [\"index\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd441fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>create new vignette on project team grading wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app crashes when darryl visits messagesscreen ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>missing onrequeststart rolecheck dont always w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>describe the bug i noticed i now have the opti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>describe the bug h make hash 1 2 3 4 5 make ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112304</th>\n",
       "      <td>with alertlistings collections passed in to qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112305</th>\n",
       "      <td>for some reason the datetime in planner is not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112306</th>\n",
       "      <td>hi all i found some mistakes in our document s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112307</th>\n",
       "      <td>id 0x7b7d2f7b7d2f7b6578706f727465645f6e616d657...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112308</th>\n",
       "      <td>chefsale i believe you already work on this so...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112309 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text_clean  label\n",
       "0       create new vignette on project team grading wi...      0\n",
       "1       app crashes when darryl visits messagesscreen ...      0\n",
       "2       missing onrequeststart rolecheck dont always w...      0\n",
       "3       describe the bug i noticed i now have the opti...      0\n",
       "4       describe the bug h make hash 1 2 3 4 5 make ha...      0\n",
       "...                                                   ...    ...\n",
       "112304  with alertlistings collections passed in to qu...      1\n",
       "112305  for some reason the datetime in planner is not...      1\n",
       "112306  hi all i found some mistakes in our document s...      1\n",
       "112307  id 0x7b7d2f7b7d2f7b6578706f727465645f6e616d657...      1\n",
       "112308  chefsale i believe you already work on this so...      1\n",
       "\n",
       "[112309 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44741770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60% trainig, 20% validate, 20% test. Seed None.\n",
    "# Test 80-10-10 and 70-15-15\n",
    "train , validate , test = train_validate_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a1eb3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index(\"label\" , inplace = True)\n",
    "validate.set_index(\"label\" , inplace = True)\n",
    "test.set_index(\"label\" , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7997ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>describe the bug when using connectorcreate in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the exporter appears to be randomly ordering t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forum posthttpswwwbryntumcomforumviewtopicphpf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if an incorrect formation is loaded or misspel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>section 3 talks about the challenges of 0rtt b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>using the quorum intersection checker provided...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cve202123337 high severity vulnerability detai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>background we need to ensure proper loading an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mit license policy violation detected in lodas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>browser firefox 1000 uaheader mozilla50 window...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22463 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_clean\n",
       "label                                                   \n",
       "0      describe the bug when using connectorcreate in...\n",
       "0      the exporter appears to be randomly ordering t...\n",
       "0      forum posthttpswwwbryntumcomforumviewtopicphpf...\n",
       "0      if an incorrect formation is loaded or misspel...\n",
       "1      section 3 talks about the challenges of 0rtt b...\n",
       "...                                                  ...\n",
       "0      using the quorum intersection checker provided...\n",
       "1      cve202123337 high severity vulnerability detai...\n",
       "1      background we need to ensure proper loading an...\n",
       "1      mit license policy violation detected in lodas...\n",
       "0      browser firefox 1000 uaheader mozilla50 window...\n",
       "\n",
       "[22463 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f88b9ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 22463\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 67385\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 22461\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert from Pandas DataFrame to Hugging Face datasets\n",
    "tds = Dataset.from_pandas(train)\n",
    "vds = Dataset.from_pandas(validate)\n",
    "testds = Dataset.from_pandas(test)\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds[\"test\"] = testds\n",
    "ds[\"train\"] = tds\n",
    "ds[\"validate\"] = vds\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e4d802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ds[\"train\"]\n",
    "valid_dataset = ds[\"validate\"]\n",
    "test_ds = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b258eff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_clean': 'thanks for ardi it is exactly what i was planning to write but already written  the little mini serial monitor in attachandwatch is great especially with how it integrates with the other attachandwatch functionality stopping during upload but it seems to assume 115200 baud thats a reasonable assumption to be sure but it seems worth adding some sort of configuration parameter maybe something that can end up in ardijson this is low priority since most sensible people use 115200 baud anyway its the fastest widely supported serial baud rate however it should probably be documented',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfaf2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf1f6948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_id, num_labels=num_labels)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "# optim = torch.optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0276267b",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "121ba546",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52afcc07",
   "metadata": {},
   "source": [
    "    Tokenizing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b051c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecfbf7831f14f76b32bbde4658bd26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67385 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab010cd8b1f49618986772504608eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22461 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd3ce38df094642a42542bf25c583bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenize the dataset to the correct input for the transformer model.\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text_clean\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "valid_dataset = valid_dataset.map(tokenize, batched=True, batch_size=len(valid_dataset))\n",
    "test_dataset = test_ds.map(tokenize, batched=True, batch_size=len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b9aa77",
   "metadata": {},
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d3c7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    save_strategy=save_strategy,\n",
    "    save_steps=save_steps,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a67c4f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    " trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1401b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21060' max='21060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21060/21060 1:59:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.448300</td>\n",
       "      <td>0.452657</td>\n",
       "      <td>0.760963</td>\n",
       "      <td>[0.68906006 0.80585789]</td>\n",
       "      <td>[0.85168218 0.72001809]</td>\n",
       "      <td>[0.57858393 0.91493554]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.394700</td>\n",
       "      <td>0.452800</td>\n",
       "      <td>0.770981</td>\n",
       "      <td>[0.76633052 0.77544962]</td>\n",
       "      <td>[0.71897375 0.82784975]</td>\n",
       "      <td>[0.82036569 0.72928812]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.262000</td>\n",
       "      <td>0.551925</td>\n",
       "      <td>0.779484</td>\n",
       "      <td>[0.74841266 0.80372499]</td>\n",
       "      <td>[0.78330675 0.776731  ]</td>\n",
       "      <td>[0.71649485 0.83266278]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.175500</td>\n",
       "      <td>0.919881</td>\n",
       "      <td>0.779573</td>\n",
       "      <td>[0.75939155 0.79663175]</td>\n",
       "      <td>[0.75891209 0.79705737]</td>\n",
       "      <td>[0.75987162 0.79620659]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.102700</td>\n",
       "      <td>1.183411</td>\n",
       "      <td>0.777214</td>\n",
       "      <td>[0.75879688 0.79301787]</td>\n",
       "      <td>[0.75219801 0.79903309]</td>\n",
       "      <td>[0.76551255 0.78709254]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21060, training_loss=0.2807473910160554, metrics={'train_runtime': 7186.3586, 'train_samples_per_second': 46.884, 'train_steps_per_second': 2.931, 'total_flos': 4.46315782921728e+16, 'train_loss': 0.2807473910160554, 'epoch': 5.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0d798d",
   "metadata": {},
   "source": [
    "* Training loss: Difference between the predictons made by the model on the training dataset vs on the actual data.\n",
    "* Validation loss: how well the model functions on unseen data.\n",
    "* Accuracy: How much the model gets correct. number of correct Prediction / total number of predictions.\n",
    "* F1: consider both precision and recall. \n",
    "* Precision: Accuracy of positive predictions. Percison TP = TP + FP. How often the model is correct.\n",
    "* Recall: True positive rate. how many items the model gets correct from the total amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d084bff",
   "metadata": {},
   "source": [
    "### Training loss decreases, valdiation loss increases = Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4d92edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1404' max='702' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [702/702 04:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate valdiation set\n",
    "eval_result = trainer.evaluate(eval_dataset=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1850e48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.7772138373180179\n",
      "\n",
      "eval_f1 = [0.75879688 0.79301787]\n",
      "\n",
      "eval_loss = 1.1834113597869873\n",
      "\n",
      "eval_precision = [0.75219801 0.79903309]\n",
      "\n",
      "eval_recall = [0.76551255 0.78709254]\n",
      "\n",
      "eval_runtime = 144.5051\n",
      "\n",
      "eval_samples_per_second = 155.434\n",
      "\n",
      "eval_steps_per_second = 4.858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(eval_result.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e9b1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data set\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22a71263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.7770110848951609\n",
      "\n",
      "eval_f1 = [0.76259538 0.7897763 ]\n",
      "\n",
      "eval_loss = 1.184050440788269\n",
      "\n",
      "eval_precision = [0.76219801 0.79014108]\n",
      "\n",
      "eval_recall = [0.76299317 0.78941186]\n",
      "\n",
      "eval_runtime = 144.5711\n",
      "\n",
      "eval_samples_per_second = 155.377\n",
      "\n",
      "eval_steps_per_second = 4.856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(test_results.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4277b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir + \"_local\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dbe7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "    \n",
    "classifier = pipeline(\"text-classification\", model=\"./model_local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d56beb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24be2171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9585654139518738}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this does not need to be done fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72379384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9984287619590759}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this is super important\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c9e9e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9995484948158264}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this bug has super high impact on the project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a8a58",
   "metadata": {},
   "source": [
    "## Important to delete large objects to free memory \n",
    "del train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5efc2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "del valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3e30eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55b3792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b33730a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 26 14:32:59 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti      On | 00000000:01:00.0 Off |                  N/A |\n",
      "| 23%   42C    P2               62W / 250W|    949MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti      On | 00000000:23:00.0 Off |                  N/A |\n",
      "| 42%   69C    P2              250W / 250W|   9213MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti      On | 00000000:41:00.0 Off |                  N/A |\n",
      "| 42%   70C    P2              249W / 250W|   9213MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti      On | 00000000:61:00.0 Off |                  N/A |\n",
      "| 36%   61C    P2              249W / 250W|   9213MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti      On | 00000000:81:00.0 Off |                  N/A |\n",
      "| 23%   43C    P2               50W / 250W|   1307MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti      On | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 22%   29C    P8               17W / 250W|      5MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti      On | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 42%   63C    P2               96W / 250W|   1215MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti      On | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 39%   65C    P2              250W / 250W|   9213MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    1   N/A  N/A   2462076      C   ...ml/home/limeng/torch_env/bin/python     9206MiB |\n",
      "|    2   N/A  N/A   2462077      C   ...ml/home/limeng/torch_env/bin/python     9206MiB |\n",
      "|    3   N/A  N/A   2462078      C   ...ml/home/limeng/torch_env/bin/python     9206MiB |\n",
      "|    6   N/A  N/A   3571331      C   ...ftware/Anaconda3/2020.11/bin/python     1210MiB |\n",
      "|    7   N/A  N/A   2462079      C   ...ml/home/limeng/torch_env/bin/python     9206MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0b1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
