{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2647ffbf",
   "metadata": {},
   "source": [
    "# Importsand preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679adbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import datasets\n",
    "import transformers\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8780e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !watch -n 0.5 nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41b2b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1+cu117\n",
      "CUDA version: 11.7\n",
      "cuDNN version: 8500\n",
      "Current device: 0\n",
      "Is cuda avaibable: True\n"
     ]
    }
   ],
   "source": [
    "print(f'PyTorch version: {torch.__version__}')  # 1.9.1+cu111\n",
    "print(f'CUDA version: {torch.version.cuda}')  # 11.1\n",
    "print(f'cuDNN version: {torch.backends.cudnn.version()}')  # 8005\n",
    "print(f'Current device: {torch.cuda.current_device()}')  # 0\n",
    "print(f'Is cuda available: {torch.cuda.is_available()}')  # TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c465b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.32.1\n",
      "Datasets version: 2.14.4\n"
     ]
    }
   ],
   "source": [
    "print(f'Transformers version: {transformers.__version__}')\n",
    "print(f'Datasets version: {datasets.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eae1f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent a warning related to the tokenization process in the transformers library. \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "# Makes CUDA operations synchronous\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66612228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 19 11:02:20 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti      On | 00000000:01:00.0 Off |                  N/A |\n",
      "| 24%   44C    P2               62W / 250W|    949MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti      On | 00000000:23:00.0 Off |                  N/A |\n",
      "| 42%   70C    P2              238W / 250W|   7623MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti      On | 00000000:41:00.0 Off |                  N/A |\n",
      "| 43%   71C    P2              237W / 250W|   7623MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti      On | 00000000:61:00.0 Off |                  N/A |\n",
      "| 36%   62C    P2              234W / 250W|   7623MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti      On | 00000000:81:00.0 Off |                  N/A |\n",
      "| 23%   40C    P2               49W / 250W|   1307MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti      On | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 22%   30C    P8               17W / 250W|      5MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti      On | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 23%   36C    P8               21W / 250W|      5MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti      On | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 39%   65C    P2              237W / 250W|   7623MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    1   N/A  N/A   2631678      C   ...ml/home/limeng/torch_env/bin/python     7616MiB |\n",
      "|    2   N/A  N/A   2631679      C   ...ml/home/limeng/torch_env/bin/python     7616MiB |\n",
      "|    3   N/A  N/A   2631680      C   ...ml/home/limeng/torch_env/bin/python     7616MiB |\n",
      "|    7   N/A  N/A   2631681      C   ...ml/home/limeng/torch_env/bin/python     7616MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Find the GPU with the least memory usage.\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3811e177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 |   0% |  8% |\n",
      "|  1 | 100% | 68% |\n",
      "|  2 | 100% | 68% |\n",
      "|  3 | 100% | 68% |\n",
      "|  4 |   0% | 12% |\n",
      "|  5 |   0% |  0% |\n",
      "|  6 |   0% |  0% |\n",
      "|  7 | 100% | 68% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU  | MEM |\n",
      "-------------------\n",
      "|  0 |   0% |  8% |\n",
      "|  1 | 100% | 68% |\n",
      "|  2 | 100% | 68% |\n",
      "|  3 | 100% | 68% |\n",
      "|  4 |   0% | 12% |\n",
      "|  5 |   0% |  0% |\n",
      "|  6 |   0% |  1% |\n",
      "|  7 | 100% | 68% |\n"
     ]
    }
   ],
   "source": [
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    # free unreferenced tensors from the GPU memory.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37bc1a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>describe the bug when i add a folder path and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>describe the bug after invoking the search bar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the current reports are all generated by sampl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e4e is generating in place if i have an elemen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>excelsior edgarf the sandbox server is not res...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19606</th>\n",
       "      <td>krav antall maps i mappen maps skal være høyer...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19607</th>\n",
       "      <td>some routes do throw exceptions other than the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19608</th>\n",
       "      <td>add post authresetrequest route which receives...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19609</th>\n",
       "      <td>add forgot password button on login page add r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19610</th>\n",
       "      <td>currently our eventmonitor spikemonitor return...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19611 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_clean  label\n",
       "0      describe the bug when i add a folder path and ...      0\n",
       "1      describe the bug after invoking the search bar...      0\n",
       "2      the current reports are all generated by sampl...      0\n",
       "3      e4e is generating in place if i have an elemen...      0\n",
       "4      excelsior edgarf the sandbox server is not res...      0\n",
       "...                                                  ...    ...\n",
       "19606  krav antall maps i mappen maps skal være høyer...      2\n",
       "19607  some routes do throw exceptions other than the...      2\n",
       "19608  add post authresetrequest route which receives...      2\n",
       "19609  add forgot password button on login page add r...      2\n",
       "19610  currently our eventmonitor spikemonitor return...      2\n",
       "\n",
       "[19611 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"csv/priority_high_or_not_clean\" , index_col = 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0a3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller and farter than bert.\n",
    "base_model_id = \"distilbert-base-uncased\"\n",
    "\n",
    "epochs = 5 #Number of full cyles through the training set.\n",
    "num_labels = 3 #Number of labels, high, med, low priority.\n",
    "learning_rate = 5e-5 # Rate the model updates based on the data its trained on.\n",
    "train_batch_size = 16 # Number of training examples in one iteration.\n",
    "eval_batch_size = 32 # Number evalutaion examples in on iteratoion.\n",
    "save_strategy = \"no\" # Should the model be saved automatically during training.\n",
    "save_steps = 500 # How often to save the model during training. No effect since no over.\n",
    "logging_steps = 100\n",
    "model_dir = \"./model\" #Where to save model\n",
    "\n",
    "# Use early stopping to prevent overfitting\n",
    "#load_best_model_at_end=True\n",
    "#metric_for_best_model=\"eval_loss\"\n",
    "#greater_is_better=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "471521d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split dataframe into three parts: training, validation and testing.\n",
    "def train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    # Shuffle index of dataframe\n",
    "    perm = np.random.permutation(df.index)\n",
    "    \n",
    "    df_length = len(df.index)\n",
    "    \n",
    "    # Number of row in training set\n",
    "    train_end = int(train_percent * df_length)\n",
    "    # Number of rows in validate set\n",
    "    validate_end = int(validate_percent * df_length) + train_end\n",
    "    \n",
    "    # From start to train end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    # From train_end to validate_end\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    # From validate to the last row in dataframe.\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51965d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops rows with missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36ca91c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>describe the bug when i add a folder path and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>describe the bug after invoking the search bar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>the current reports are all generated by sampl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>e4e is generating in place if i have an elemen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>excelsior edgarf the sandbox server is not res...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19601</th>\n",
       "      <td>19606</td>\n",
       "      <td>krav antall maps i mappen maps skal være høyer...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19602</th>\n",
       "      <td>19607</td>\n",
       "      <td>some routes do throw exceptions other than the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19603</th>\n",
       "      <td>19608</td>\n",
       "      <td>add post authresetrequest route which receives...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19604</th>\n",
       "      <td>19609</td>\n",
       "      <td>add forgot password button on login page add r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19605</th>\n",
       "      <td>19610</td>\n",
       "      <td>currently our eventmonitor spikemonitor return...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19606 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                         text_clean  label\n",
       "0          0  describe the bug when i add a folder path and ...      0\n",
       "1          1  describe the bug after invoking the search bar...      0\n",
       "2          2  the current reports are all generated by sampl...      0\n",
       "3          3  e4e is generating in place if i have an elemen...      0\n",
       "4          4  excelsior edgarf the sandbox server is not res...      0\n",
       "...      ...                                                ...    ...\n",
       "19601  19606  krav antall maps i mappen maps skal være høyer...      2\n",
       "19602  19607  some routes do throw exceptions other than the...      2\n",
       "19603  19608  add post authresetrequest route which receives...      2\n",
       "19604  19609  add forgot password button on login page add r...      2\n",
       "19605  19610  currently our eventmonitor spikemonitor return...      2\n",
       "\n",
       "[19606 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resets the index after dropping rows\n",
    "data.reset_index(inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c0c6649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drops the index col, better for managint the data.\n",
    "data.drop(columns= [\"index\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb6ff665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>describe the bug when i add a folder path and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>describe the bug after invoking the search bar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the current reports are all generated by sampl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e4e is generating in place if i have an elemen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>excelsior edgarf the sandbox server is not res...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19601</th>\n",
       "      <td>krav antall maps i mappen maps skal være høyer...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19602</th>\n",
       "      <td>some routes do throw exceptions other than the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19603</th>\n",
       "      <td>add post authresetrequest route which receives...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19604</th>\n",
       "      <td>add forgot password button on login page add r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19605</th>\n",
       "      <td>currently our eventmonitor spikemonitor return...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19606 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_clean  label\n",
       "0      describe the bug when i add a folder path and ...      0\n",
       "1      describe the bug after invoking the search bar...      0\n",
       "2      the current reports are all generated by sampl...      0\n",
       "3      e4e is generating in place if i have an elemen...      0\n",
       "4      excelsior edgarf the sandbox server is not res...      0\n",
       "...                                                  ...    ...\n",
       "19601  krav antall maps i mappen maps skal være høyer...      2\n",
       "19602  some routes do throw exceptions other than the...      2\n",
       "19603  add post authresetrequest route which receives...      2\n",
       "19604  add forgot password button on login page add r...      2\n",
       "19605  currently our eventmonitor spikemonitor return...      2\n",
       "\n",
       "[19606 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30aaa209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60% trainig, 20% validate, 20% test. Seed None.\n",
    "# Test 80-10-10 and 70-15-15\n",
    "train , validate , test = train_validate_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77e40e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index(\"label\" , inplace = True)\n",
    "validate.set_index(\"label\" , inplace = True)\n",
    "test.set_index(\"label\" , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e85d2be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 predelete and postdelete signals are not con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>story as a user i should be able to view my co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>current acceptance testing is written in an md...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>items with the 2pzd suffix are dependent on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature request is your feature request relate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>instances of the pangotext rendering class are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>description of problem the table htmltext stil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>after all have voted or the time ran out the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>required features create new repository reposi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>welcome to erpnext issue tracker before creati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3922 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_clean\n",
       "label                                                   \n",
       "1      1 predelete and postdelete signals are not con...\n",
       "0      story as a user i should be able to view my co...\n",
       "0      current acceptance testing is written in an md...\n",
       "1      items with the 2pzd suffix are dependent on th...\n",
       "0      feature request is your feature request relate...\n",
       "...                                                  ...\n",
       "2      instances of the pangotext rendering class are...\n",
       "1      description of problem the table htmltext stil...\n",
       "0      after all have voted or the time ran out the p...\n",
       "1      required features create new repository reposi...\n",
       "1      welcome to erpnext issue tracker before creati...\n",
       "\n",
       "[3922 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2e02d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 3922\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 11763\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['text_clean', 'label'],\n",
       "        num_rows: 3921\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert from Pandas DataFrame to Hugging Face datasets\n",
    "tds = Dataset.from_pandas(train)\n",
    "vds = Dataset.from_pandas(validate)\n",
    "testds = Dataset.from_pandas(test)\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds[\"test\"] = testds\n",
    "ds[\"train\"] = tds\n",
    "ds[\"validate\"] = vds\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67267f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ds[\"train\"]\n",
    "valid_dataset = ds[\"validate\"]\n",
    "test_ds = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b8be1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text_clean': 'description create frontend ui to upload new profile picture',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e589f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb286043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(base_model_id, num_labels=num_labels)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "# optim = torch.optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f69554c",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfe27e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe4871f",
   "metadata": {},
   "source": [
    "    Tokenizing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e9d6a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0151a1e3114b4d3b811c09a525b5e1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11763 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8e641262cc44d78a8a2ae31a37ee22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3921 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5519b0d9ccbc47fda52d67c9b6ee42ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3922 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenize the dataset to the correct input for the transformer model.\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text_clean\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "valid_dataset = valid_dataset.map(tokenize, batched=True, batch_size=len(valid_dataset))\n",
    "test_dataset = test_ds.map(tokenize, batched=True, batch_size=len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0563636b",
   "metadata": {},
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c225dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    save_strategy=save_strategy,\n",
    "    save_steps=save_steps,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b55825b9",
   "metadata": {},
   "outputs": [],
   "source": [
    " trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7a092e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3680' max='3680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3680/3680 20:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.929300</td>\n",
       "      <td>0.916628</td>\n",
       "      <td>0.577914</td>\n",
       "      <td>[0.70243118 0.00903614 0.4679691 ]</td>\n",
       "      <td>[0.60969655 0.5        0.49141221]</td>\n",
       "      <td>[0.82843602 0.00455927 0.44666088]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.806500</td>\n",
       "      <td>0.944981</td>\n",
       "      <td>0.592706</td>\n",
       "      <td>[0.71896956 0.16311167 0.43414888]</td>\n",
       "      <td>[0.61114798 0.4676259  0.54296875]</td>\n",
       "      <td>[0.87298578 0.09878419 0.36166522]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.526500</td>\n",
       "      <td>1.123213</td>\n",
       "      <td>0.554705</td>\n",
       "      <td>[0.66168038 0.27378965 0.51955944]</td>\n",
       "      <td>[0.69805366 0.3037037  0.46216216]</td>\n",
       "      <td>[0.62890995 0.24924012 0.59323504]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.286500</td>\n",
       "      <td>1.513756</td>\n",
       "      <td>0.563377</td>\n",
       "      <td>[0.67908512 0.30362538 0.49890206]</td>\n",
       "      <td>[0.67573909 0.3018018  0.50533808]</td>\n",
       "      <td>[0.68246445 0.30547112 0.49262793]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>1.882784</td>\n",
       "      <td>0.563377</td>\n",
       "      <td>[0.68118997 0.30983847 0.49208503]</td>\n",
       "      <td>[0.67345994 0.29971591 0.51417769]</td>\n",
       "      <td>[0.68909953 0.32066869 0.47181266]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3680, training_loss=0.5575704426869103, metrics={'train_runtime': 1252.8296, 'train_samples_per_second': 46.946, 'train_steps_per_second': 2.937, 'total_flos': 7791208994626560.0, 'train_loss': 0.5575704426869103, 'epoch': 5.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dbcd7a",
   "metadata": {},
   "source": [
    "* Training loss: Difference between the predictons made by the model on the training dataset vs on the actual data.\n",
    "* Validation loss: how well the model functions on unseen data.\n",
    "* Accuracy: How much the model gets correct. number of correct Prediction / total number of predictions.\n",
    "* F1: consider both precision and recall. \n",
    "* Precision: Accuracy of positive predictions. Percison TP = TP + FP. How often the model is correct.\n",
    "* Recall: True positive rate. how many items the model gets correct from the total amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1fbea",
   "metadata": {},
   "source": [
    "### Training loss decreases, valdiation loss increases = Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9858eea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='246' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [123/123 00:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate valdiation set\n",
    "eval_result = trainer.evaluate(eval_dataset=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6513085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.5633766896199949\n",
      "\n",
      "eval_f1 = [0.68118997 0.30983847 0.49208503]\n",
      "\n",
      "eval_loss = 1.882784128189087\n",
      "\n",
      "eval_precision = [0.67345994 0.29971591 0.51417769]\n",
      "\n",
      "eval_recall = [0.68909953 0.32066869 0.47181266]\n",
      "\n",
      "eval_runtime = 25.2019\n",
      "\n",
      "eval_samples_per_second = 155.584\n",
      "\n",
      "eval_steps_per_second = 4.881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(eval_result.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf47e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data set\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d03fd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5.0\n",
      "\n",
      "eval_accuracy = 0.5520142784293728\n",
      "\n",
      "eval_f1 = [0.67946894 0.31284153 0.4653099 ]\n",
      "\n",
      "eval_loss = 1.9196563959121704\n",
      "\n",
      "eval_precision = [0.67276995 0.29817708 0.49121094]\n",
      "\n",
      "eval_recall = [0.68630268 0.32902299 0.44200351]\n",
      "\n",
      "eval_runtime = 25.2771\n",
      "\n",
      "eval_samples_per_second = 155.16\n",
      "\n",
      "eval_steps_per_second = 4.866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(test_results.items()):\n",
    "    print(f\"{key} = {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6393324",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir + \"_local\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "473bd687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "    \n",
    "classifier = pipeline(\"text-classification\", model=\"./model_local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "595362bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b84fbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9985688924789429}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"this does not need to be done fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0b270b",
   "metadata": {},
   "source": [
    "## Important to delete large objects to free memory \n",
    "del train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40617a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "del valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6401bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bb7f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23dc1357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 19 11:24:21 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti      On | 00000000:01:00.0 Off |                  N/A |\n",
      "| 24%   44C    P2               63W / 250W|    949MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti      On | 00000000:23:00.0 Off |                  N/A |\n",
      "| 43%   70C    P2              258W / 250W|   7623MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 2080 Ti      On | 00000000:41:00.0 Off |                  N/A |\n",
      "| 43%   71C    P2              257W / 250W|   7623MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 2080 Ti      On | 00000000:61:00.0 Off |                  N/A |\n",
      "| 37%   62C    P2              259W / 250W|   7623MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 2080 Ti      On | 00000000:81:00.0 Off |                  N/A |\n",
      "| 24%   44C    P2               51W / 250W|   1307MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 2080 Ti      On | 00000000:A1:00.0 Off |                  N/A |\n",
      "| 22%   30C    P8               17W / 250W|      5MiB / 11264MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 2080 Ti      On | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 42%   65C    P2               86W / 250W|   1215MiB / 11264MiB |      4%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 2080 Ti      On | 00000000:E1:00.0 Off |                  N/A |\n",
      "| 39%   65C    P2              249W / 250W|   7623MiB / 11264MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    1   N/A  N/A   2631678      C   ...ml/home/limeng/torch_env/bin/python     7616MiB |\n",
      "|    2   N/A  N/A   2631679      C   ...ml/home/limeng/torch_env/bin/python     7616MiB |\n",
      "|    3   N/A  N/A   2631680      C   ...ml/home/limeng/torch_env/bin/python     7616MiB |\n",
      "|    6   N/A  N/A    807614      C   ...ftware/Anaconda3/2020.11/bin/python     1210MiB |\n",
      "|    7   N/A  N/A   2631681      C   ...ml/home/limeng/torch_env/bin/python     7616MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb6069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
