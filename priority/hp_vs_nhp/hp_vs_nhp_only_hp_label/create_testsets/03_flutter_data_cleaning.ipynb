{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "We want the class with labels as numerical value and the body with clean text.\n",
    "\n",
    "This will remove:\n",
    "* duplicates\n",
    "* NaN entires\n",
    "* non english\n",
    "* url, html\n",
    "\n",
    "* make it lowercase\n",
    "* combine title and body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../../../scripts_shared/\")\n",
    "from preprocess_text import preprocess_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV into a dataframe\n",
    "filename = \"csv/flutter_testset.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number or different labels\n",
    "df.labels.value_counts().to_frame()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data based on labels. Contains P0 and P1 in one dataframe, the rest in another\n",
    "\n",
    "pattern = 'P(1|0)'\n",
    "# Check if 'labels' contains the pattern\n",
    "hp = df[df['labels'].str.contains(pattern)]\n",
    "# Reset index\n",
    "hp = hp.reset_index(drop=True)\n",
    "hp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove pattern from df\n",
    "random = df[~df['labels'].str.contains(pattern)]\n",
    "random = random.reset_index(drop=True)\n",
    "random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing in triage since these issues are not assigned a priority\n",
    "pattern = 'in triage'\n",
    "# Remove pattern from df\n",
    "random = random[~random['labels'].str.contains(pattern)]\n",
    "random = random.reset_index(drop=True)\n",
    "random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.labels.value_counts().to_frame()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number or different labels\n",
    "hp.labels.value_counts().to_frame()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Give each priority a label by number.\n",
    "# 'Label encoding'. Makes is easier for machine learning models to work with categorical data.\n",
    "hp[\"label\"] = 1\n",
    "hp[\"class\"] = \"high_priority\"\n",
    "hp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random[\"label\"] = 0\n",
    "random[\"class\"] = \"not_high_priority\" \n",
    "random.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates by the content of the title\n",
    "high_priority = hp.drop_duplicates(subset=['title'], keep='last')\n",
    "high_priority.dropna(inplace=True)\n",
    "high_priority.reset_index(inplace=True)\n",
    "high_priority.drop(columns=[\"index\"] , inplace= True)\n",
    "high_priority[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates by the content of the title\n",
    "not_high_priority = random.drop_duplicates(subset=['title'], keep='last')\n",
    "not_high_priority.dropna(inplace=True)\n",
    "not_high_priority.reset_index(inplace=True)\n",
    "not_high_priority.drop(columns=[\"index\"] , inplace= True)\n",
    "not_high_priority[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_priority.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = high_priority[\"class\"].value_counts()\n",
    "label_counts_nhp = not_high_priority[\"class\"].value_counts()\n",
    "print(label_counts)\n",
    "not_high_priority_count = label_counts_nhp[\"not_high_priority\"]\n",
    "print(not_high_priority_count)\n",
    "hp_count = label_counts[\"high_priority\"]\n",
    "hp_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_high_priority = not_high_priority.sample(frac=hp_count/not_high_priority_count, random_state=42)\n",
    "not_high_priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_priority = pd.concat([high_priority,not_high_priority] , ignore_index = True)\n",
    "all_priority.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "all_priority[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_priority[\"title\"][0])\n",
    "print(all_priority[\"body\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy content of body to a new col named text\n",
    "all_priority[\"text\"] = all_priority[\"title\"] + \" \" + all_priority[\"body\"]\n",
    "all_priority.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_priority[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new dataframe with only text, label and class cols.\n",
    "all_priority_subset = all_priority[[\"text\" , \"label\" , \"class\"]]\n",
    "all_priority_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to string\n",
    "all_priority_subset[\"text_str\"] = all_priority_subset['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_priority_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data.\n",
    "all_priority_subset[\"text_clean\"] = all_priority_subset[\"text_str\"].map(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset with text_clean and label\n",
    "priority_label_text = all_priority_subset[[\"text_clean\" , \"label\"]]\n",
    "priority_label_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to dropna here since cleaning function returns NaN for not english text.\n",
    "priority_label_text.dropna(inplace=True)\n",
    "priority_label_text.reset_index(inplace=True)\n",
    "priority_label_text.drop(columns=[\"index\"] , inplace= True)\n",
    "\n",
    "priority_label_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Split the dataset into two based on the label\n",
    "df_majority = priority_label_text[priority_label_text['label'] == 1]\n",
    "df_minority = priority_label_text[priority_label_text['label'] == 0]\n",
    "\n",
    "# Undersample the majority class\n",
    "df_majority_undersampled = resample(df_majority, \n",
    "                                     replace=False,    # sample without replacement\n",
    "                                     n_samples=len(df_minority),     # to match minority class\n",
    "                                     random_state=123) # reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "df_balanced = pd.concat([df_majority_undersampled, df_minority])\n",
    "\n",
    "# Shuffle the dataset to avoid any ordering bias\n",
    "df_balanced = df_balanced.sample(frac=1).reset_index(drop=True)\n",
    "priority_label_text = df_balanced\n",
    "priority_label_text[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataset with clean text and labels.\n",
    "# 1 = high priority, 0 = not high priority\n",
    "file_name = f\"csv/clean_flutter_testset.csv\"\n",
    "priority_label_text.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri = pd.read_csv(file_name)\n",
    "pri"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c8c1d29baca421c992713322bc02d129892a44846f1f6fab21a46344afe0421"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
