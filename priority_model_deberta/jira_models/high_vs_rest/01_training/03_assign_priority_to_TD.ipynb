{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c8e29e",
   "metadata": {},
   "source": [
    "# Training\n",
    "This notebook trains the model with 3 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc2a6e9-5307-4fe4-85eb-c93b411ea352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 10:27:52] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 10:27:52] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 10:27:52] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 10:27:52] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 10:27:52] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 10:27:55] We saw that you have a AMD EPYC 7642 48-Core Processor but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 10:27:55] CPU Model on constant consumption mode: AMD EPYC 7642 48-Core Processor\n",
      "[codecarbon INFO @ 10:27:55] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 10:27:55]   Platform system: Linux-5.14.0-362.8.1.el9_3.x86_64-x86_64-with-glibc2.34\n",
      "[codecarbon INFO @ 10:27:55]   Python version: 3.11.3\n",
      "[codecarbon INFO @ 10:27:55]   CodeCarbon version: 2.3.4\n",
      "[codecarbon INFO @ 10:27:55]   Available RAM : 256.000 GB\n",
      "[codecarbon INFO @ 10:27:55]   CPU count: 24\n",
      "[codecarbon INFO @ 10:27:55]   CPU model: AMD EPYC 7642 48-Core Processor\n",
      "[codecarbon INFO @ 10:27:55]   GPU count: 1\n",
      "[codecarbon INFO @ 10:27:55]   GPU model: 1 x NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "from codecarbon import EmissionsTracker\n",
    "import logging\n",
    "output_directory = \"/fp/homes01/u01/ec-krimhau/thesis_code/\"\n",
    "\n",
    "tracker = EmissionsTracker(output_dir=output_directory)\n",
    "tracker.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0327e264-b371-42d5-afa0-c46c53b0382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('codecarbon').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad35c23",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac26d5cb-fc6b-4b1a-83bb-dbd1428303f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Need this to load the packages correc in Fox ml nodes.\n",
    "sys.path.append(\"/fp/homes01/u01/ec-krimhau/.local/lib/python3.11/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8674f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import joblib\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "\n",
    "# For Transformer Models\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, AdamW\n",
    "from transformers import DataCollatorWithPadding\n",
    "import datasets\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315755f0-f5e7-403d-aaef-9e5181f97867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env file\n",
    "%load_ext dotenv\n",
    "%dotenv /fp/homes01/u01/ec-krimhau/thesis_code/.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2acc4972-259a-40ab-9c55-c8e8d5386dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /fp/homes01/u01/ec-krimhau/thesis_code/jira/priority_model/highest_vs_rest/deberta/01_training/01_train_highest_vs_rest.ipynb.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/fp/homes01/u01/ec-krimhau/.local/lib/python3.11/site-packages/wandb/__main__.py\", line 3, in <module>\n",
      "    cli.cli(prog_name=\"python -m wandb\")\n",
      "  File \"/cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages/click/core.py\", line 1130, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages/click/core.py\", line 1055, in main\n",
      "    rv = self.invoke(ctx)\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages/click/core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages/click/core.py\", line 1404, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages/click/core.py\", line 760, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/fp/homes01/u01/ec-krimhau/.local/lib/python3.11/site-packages/wandb/cli/cli.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/fp/homes01/u01/ec-krimhau/.local/lib/python3.11/site-packages/wandb/cli/cli.py\", line 289, in service\n",
      "    server.serve()\n",
      "  File \"/fp/homes01/u01/ec-krimhau/.local/lib/python3.11/site-packages/wandb/sdk/service/server.py\", line 114, in serve\n",
      "    self._inform_used_ports(sock_port=sock_port)\n",
      "  File \"/fp/homes01/u01/ec-krimhau/.local/lib/python3.11/site-packages/wandb/sdk/service/server.py\", line 52, in _inform_used_ports\n",
      "    pf.write(self._port_fname)\n",
      "  File \"/fp/homes01/u01/ec-krimhau/.local/lib/python3.11/site-packages/wandb/sdk/service/port_file.py\", line 21, in write\n",
      "    f = tempfile.NamedTemporaryFile(prefix=bname, dir=dname, mode=\"w\", delete=False)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/software/EL9/easybuild/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/tempfile.py\", line 563, in NamedTemporaryFile\n",
      "    file = _io.open(dir, mode, buffering=buffering,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/software/EL9/easybuild/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/tempfile.py\", line 560, in opener\n",
      "    fd, name = _mkstemp_inner(dir, prefix, suffix, flags, output_type)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/software/EL9/easybuild/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/tempfile.py\", line 256, in _mkstemp_inner\n",
      "    fd = _os.open(file, flags, 0o600)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/localscratch/527538/tmpg5tc4ncq/port-3853622.txts24y6vcp'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhaugerud-kristian\u001b[0m (\u001b[33mkrimhau\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /fp/homes01/u01/ec-krimhau/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get wandb api key from .env file\n",
    "wandb_api_key = os.getenv('WANDB_API_KEY')\n",
    "# Login to wandb to track results\n",
    "wandb.login(key = wandb_api_key) # API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a503c8f6-da8a-4f62-b755-b31f3b77f3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TD_Chromium_dataset_clean.csv  TD_dataset_clean.csv  TD_jira_TD_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "td_file_path = \"/fp/projects01/ec307/ec-krimhau/TD_dataset\"\n",
    "td_file_name = \"TD_Chromium_dataset_clean.csv\"\n",
    "TD_dataset = pd.read_csv(f\"{td_file_path}/{td_file_name}\", index_col = 0)\n",
    "!ls /fp/projects01/ec307/ec-krimhau/TD_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af90502f-4c48-4e04-a409-9fba556a00ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>network throttling does not throttle uploads u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parallelize test execution to speed up buildbo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>netfilter switch to pure pullbased filter api ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>huge animated gifs can lead to scroll jank use...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>issues with pdf viewer and iframe useragent  w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>wtperf multi btree wtperf dump core mac issues...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>scrub dirty page rather evicting single page r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>include src include wiredtigerext h problemati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>java freed memory overwrite handle close cause...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>fix test case false positive  issues relating ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     network throttling does not throttle uploads u...      1\n",
       "1     parallelize test execution to speed up buildbo...      1\n",
       "2     netfilter switch to pure pullbased filter api ...      1\n",
       "3     huge animated gifs can lead to scroll jank use...      1\n",
       "4     issues with pdf viewer and iframe useragent  w...      1\n",
       "...                                                 ...    ...\n",
       "1495  wtperf multi btree wtperf dump core mac issues...      0\n",
       "1496  scrub dirty page rather evicting single page r...      1\n",
       "1497  include src include wiredtigerext h problemati...      0\n",
       "1498  java freed memory overwrite handle close cause...      1\n",
       "1499  fix test case false positive  issues relating ...      0\n",
       "\n",
       "[1500 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TD_dataset = pd.read_csv(f\"{td_file_path}/{td_file_name}\", index_col = 0)\n",
    "TD_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7fcade8-1e6d-418a-acd1-c860be6c3c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmyc4k23vc47\n"
     ]
    }
   ],
   "source": [
    "# Function to generate a unique random identifier for experiment tracking.\n",
    "def id_generator(size=12, chars=string.ascii_lowercase + string.digits):\n",
    "    return ''.join(random.SystemRandom().choice(chars) for _ in range(size))\n",
    "\n",
    "\n",
    "HASH_NAME = 'kmyc4k23vc47'\n",
    "print(HASH_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec0aa632-8739-4e63-bde0-5f4fc123f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config for the model\n",
    "CONFIG = {\"seed\": 42,\n",
    "          \"epochs\": 3,\n",
    "          \"model_name\": \"microsoft/deberta-v3-base\",\n",
    "          \"train_batch_size\": 8,\n",
    "          \"valid_batch_size\": 16,\n",
    "          \"max_length\": 512,\n",
    "          \"learning_rate\": 1e-5,\n",
    "          \"scheduler\": 'CosineAnnealingLR',\n",
    "          \"min_lr\": 1e-6,\n",
    "          \"T_max\": 500,\n",
    "          \"weight_decay\": 1e-6,\n",
    "          \"n_fold\": 3,\n",
    "          \"n_accumulate\": 1,\n",
    "          \"num_classes\": 2,\n",
    "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "          \"hash_name\": HASH_NAME,\n",
    "          \"_wandb_kernel\": \"deb\",\n",
    "          }\n",
    "\n",
    "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n",
    "CONFIG['group'] = f'{HASH_NAME}-Baseline'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31dc5cac-8438-438d-b45b-e2dab3b74949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5220e6af-9036-4a04-8808-b374d2c8728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the data into train and test. Validation is done using KFold.\n",
    "def train_test_split(df, train_percent=.85, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    test = df.iloc[perm[train_end:]]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08fbf305-6c3b-496b-9ffc-0fb43dca7010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "      <th>class_original</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>highest</th>\n",
       "      <td>when we do range query on simple keys it does ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highest</th>\n",
       "      <td>unhandledpromiserejectionwarning unhandled pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>Highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>the fabricunittestdaily branch failing intermi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>as a system operator i want to receive alerts ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>there is no support in datasourcetransactionma...</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>once i have imported a widget into the store i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>the spec defines an axiom of a ie singleton li...</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>to have an history on master of all csvs setup...</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highest</th>\n",
       "      <td>there are still some changes expected to be me...</td>\n",
       "      <td>1</td>\n",
       "      <td>Highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highest</th>\n",
       "      <td>crw failed to install from operatorhub because...</td>\n",
       "      <td>1</td>\n",
       "      <td>Highest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110716 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text_clean  label  \\\n",
       "class                                                               \n",
       "highest  when we do range query on simple keys it does ...      1   \n",
       "highest  unhandledpromiserejectionwarning unhandled pro...      1   \n",
       "rest     the fabricunittestdaily branch failing intermi...      0   \n",
       "rest     as a system operator i want to receive alerts ...      0   \n",
       "rest     there is no support in datasourcetransactionma...      0   \n",
       "...                                                    ...    ...   \n",
       "rest     once i have imported a widget into the store i...      0   \n",
       "rest     the spec defines an axiom of a ie singleton li...      0   \n",
       "rest     to have an history on master of all csvs setup...      0   \n",
       "highest  there are still some changes expected to be me...      1   \n",
       "highest  crw failed to install from operatorhub because...      1   \n",
       "\n",
       "        class_original  \n",
       "class                   \n",
       "highest        Highest  \n",
       "highest        Highest  \n",
       "rest            Medium  \n",
       "rest            Medium  \n",
       "rest            Medium  \n",
       "...                ...  \n",
       "rest               Low  \n",
       "rest            Medium  \n",
       "rest            Medium  \n",
       "highest        Highest  \n",
       "highest        Highest  \n",
       "\n",
       "[110716 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority_df = pd.read_csv(\"../csv/highest_vs_rest_balanced_jira.csv\" , index_col = 0)\n",
    "priority_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f33cbd6a-34c0-4cd2-9894-2ae7f51aae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values and reset index of dataframe\n",
    "priority_df = priority_df[priority_df['text_clean'].notna()]\n",
    "priority_df = priority_df.rename(columns={'text_clean': 'text'})\n",
    "priority_df = priority_df.reset_index()\n",
    "priority_df.drop(columns=[\"class\", \"class_original\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b31cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when we do range query on simple keys it does ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unhandledpromiserejectionwarning unhandled pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the fabricunittestdaily branch failing intermi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>as a system operator i want to receive alerts ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there is no support in datasourcetransactionma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110711</th>\n",
       "      <td>once i have imported a widget into the store i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110712</th>\n",
       "      <td>the spec defines an axiom of a ie singleton li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110713</th>\n",
       "      <td>to have an history on master of all csvs setup...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110714</th>\n",
       "      <td>there are still some changes expected to be me...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110715</th>\n",
       "      <td>crw failed to install from operatorhub because...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110716 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "0       when we do range query on simple keys it does ...      1\n",
       "1       unhandledpromiserejectionwarning unhandled pro...      1\n",
       "2       the fabricunittestdaily branch failing intermi...      0\n",
       "3       as a system operator i want to receive alerts ...      0\n",
       "4       there is no support in datasourcetransactionma...      0\n",
       "...                                                   ...    ...\n",
       "110711  once i have imported a widget into the store i...      0\n",
       "110712  the spec defines an axiom of a ie singleton li...      0\n",
       "110713  to have an history on master of all csvs setup...      0\n",
       "110714  there are still some changes expected to be me...      1\n",
       "110715  crw failed to install from operatorhub because...      1\n",
       "\n",
       "[110716 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abede05d-ccb8-427c-b64a-135ba811adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hp_df , test_hp_df = train_test_split(priority_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1b91f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fc38a0a-127a-4cd3-b48f-0b4396cfc4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c81cfe39-f370-4899-be2e-e99acdcbff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"index\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7a78193-7048-494e-bcb7-443982ffd50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>currently we are using usrshareelasticsearch a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>its been over hrs since the mirror has been up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there has been discussion on the mailing lists...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when elytron client tries to obtain clientconf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>need to be able to release all items at once v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94103</th>\n",
       "      <td>this was discussed in the pr args will be kept...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94104</th>\n",
       "      <td>the take and filter kernels do not currently s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94105</th>\n",
       "      <td>currently pointing to out of date links names ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94106</th>\n",
       "      <td>the chaincode build image relies on accessing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94107</th>\n",
       "      <td>if i create a converter plugin with converterk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94108 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      currently we are using usrshareelasticsearch a...      0\n",
       "1      its been over hrs since the mirror has been up...      0\n",
       "2      there has been discussion on the mailing lists...      0\n",
       "3      when elytron client tries to obtain clientconf...      1\n",
       "4      need to be able to release all items at once v...      1\n",
       "...                                                  ...    ...\n",
       "94103  this was discussed in the pr args will be kept...      0\n",
       "94104  the take and filter kernels do not currently s...      0\n",
       "94105  currently pointing to out of date links names ...      1\n",
       "94106  the chaincode build image relies on accessing ...      1\n",
       "94107  if i create a converter plugin with converterk...      1\n",
       "\n",
       "[94108 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88bf5ac1-e08c-4ed3-8e6e-e329bebc18c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    47084\n",
       "0    47024\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1902e2d0-9479-4a54-9148-7b6ddd0e44e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=CONFIG['n_fold'])\n",
    "\n",
    "for fold, ( _, val_) in enumerate(gkf.split(X=df, groups=df.text)):\n",
    "    df.loc[val_ , \"kfold\"] = int(fold)\n",
    "    \n",
    "df[\"kfold\"] = df[\"kfold\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60874b39-4bec-4d96-9973-01d6935693dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kfold  label\n",
       "0      1        15814\n",
       "       0        15556\n",
       "1      0        15783\n",
       "       1        15586\n",
       "2      0        15685\n",
       "       1        15684\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('kfold')['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "455d058b-1561-4493-bd19-11cb59be06cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>currently we are using usrshareelasticsearch a...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>its been over hrs since the mirror has been up...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there has been discussion on the mailing lists...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when elytron client tries to obtain clientconf...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>need to be able to release all items at once v...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94103</th>\n",
       "      <td>this was discussed in the pr args will be kept...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94104</th>\n",
       "      <td>the take and filter kernels do not currently s...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94105</th>\n",
       "      <td>currently pointing to out of date links names ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94106</th>\n",
       "      <td>the chaincode build image relies on accessing ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94107</th>\n",
       "      <td>if i create a converter plugin with converterk...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  kfold\n",
       "0      currently we are using usrshareelasticsearch a...      0      2\n",
       "1      its been over hrs since the mirror has been up...      0      0\n",
       "2      there has been discussion on the mailing lists...      0      0\n",
       "3      when elytron client tries to obtain clientconf...      1      1\n",
       "4      need to be able to release all items at once v...      1      2\n",
       "...                                                  ...    ...    ...\n",
       "94103  this was discussed in the pr args will be kept...      0      0\n",
       "94104  the take and filter kernels do not currently s...      0      2\n",
       "94105  currently pointing to out of date links names ...      1      2\n",
       "94106  the chaincode build image relies on accessing ...      1      2\n",
       "94107  if i create a converter plugin with converterk...      1      0\n",
       "\n",
       "[94108 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf0b8a2-2363-4668-a19d-945fb2800d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2e6cfb2-d1e2-4ef8-8694-2d18e56296a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HP_Dataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = df['text'].values\n",
    "        self.targets = df['label'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        truncation=True,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=self.max_len\n",
    "                    )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "            'target': self.targets[index]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbc28466-4efa-44b1-9486-63cc0b2d7c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorWithPadding(tokenizer=CONFIG['tokenizer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d739c680-fc15-4d64-8cf4-8902174dfe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dba820b1-375c-4a0c-970a-fd554c94ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HP_Model(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(HP_Model, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.pooler = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, CONFIG['num_classes'])\n",
    "        \n",
    "    def forward(self, ids, mask):        \n",
    "        out = self.model(input_ids=ids,attention_mask=mask,\n",
    "                         output_hidden_states=False)\n",
    "        out = self.pooler(out.last_hidden_state, mask)\n",
    "        out = self.drop(out)\n",
    "        outputs = self.fc(out)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1abf13ca-1c86-4cfe-9955-3ff4d0cafe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, labels):\n",
    "    return nn.CrossEntropyLoss()(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "013d660f-6376-45cf-9c52-2de074708b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        targets = data['target'].to(device, dtype=torch.long)\n",
    "        \n",
    "        batch_size = ids.size(0)\n",
    "\n",
    "        outputs = model(ids, mask)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "        loss.backward()\n",
    "    \n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "            optimizer.step()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77809ed9-c4a1-436f-9bc5-d806ffe6d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2df79ea9-afa8-4de5-a84b-d6dfdc826ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_classification_report(y_true, y_pred, target_names = ['Non_HP', 'HP'], digits=4):\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, target_names = target_names, digits=4))\n",
    "    \n",
    "    accuracy =round(accuracy_score(y_true, y_pred),4)\n",
    "    print(\"Accuracy =\",  accuracy)\n",
    "    f1score = round(f1_score(y_true, y_pred),4)\n",
    "    print(\"F1_score =\", f1score)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['Non_HP', 'HP'])\n",
    "    ax.yaxis.set_ticklabels(['Non_HP', 'HP'])\n",
    "    \n",
    "    return  accuracy , f1score\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0633e6f-e935-4b94-853b-f3ef01cf97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        targets = data['target'].to(device, dtype=torch.long)\n",
    "        \n",
    "        batch_size = ids.size(0)\n",
    "\n",
    "        outputs = model(ids, mask)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "\n",
    "        predictions = torch.argmax(outputs, dim=-1).flatten().tolist()\n",
    "        \n",
    "        target = targets.tolist()\n",
    "\n",
    "        y_pred.extend(predictions)\n",
    "        y_true.extend(target)\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    \n",
    "    accuracy, f1score = all_classification_report(y_true,y_pred)\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss , accuracy , f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2a01d01-3b43-4723-9874-43b38ffcbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n",
    "    # To automatically log gradients\n",
    "    wandb.watch(model, log_freq=100)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_loss = np.inf\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch)\n",
    "        \n",
    "        val_epoch_loss, accuracy , f1score = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "      \n",
    "        history['Valid accuracy'].append(accuracy)\n",
    "        history['Valid f1score'].append(f1score)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # Log the metrics\n",
    "        wandb.log({\"Train Loss\": train_epoch_loss})\n",
    "        wandb.log({\"Valid Loss\": val_epoch_loss})\n",
    "        wandb.log({\"Valid Accuracy\": accuracy})\n",
    "        wandb.log({\"Valid F1_score\": f1score})\n",
    "\n",
    "\n",
    "        \n",
    "        # deep copy the model\n",
    "        if val_epoch_loss <= best_epoch_loss:\n",
    "            print(f\"{b_}Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
    "            best_epoch_loss = val_epoch_loss\n",
    "            run.summary[\"Best Loss\"] = best_epoch_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"{HASH_NAME}-Loss-Fold-{fold}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ac45314-e0b4-4150-8e2a-06beba582112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = HP_Dataset(df_train, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "    valid_dataset = HP_Dataset(df_valid, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], collate_fn=collate_fn, \n",
    "                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], collate_fn=collate_fn,\n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3b81685-ab3f-47ca-b1de-86dc9d79fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f151c433",
   "metadata": {},
   "source": [
    "<h2> Testing Inference </h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8f36497-0ef8-4e3c-8c9e-50c92b92e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings,transformers,logging,torch\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b25e683-7c36-487f-ba36-905d9b04ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6be00e4-81ad-4264-b42a-afff577eff59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16484</th>\n",
       "      <td>iiopsecurityinvocationtestcase fails with secu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27086</th>\n",
       "      <td>it seems that we have some jars as part of pdf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51630</th>\n",
       "      <td>release olingo version</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54583</th>\n",
       "      <td>log cleaner grows buffers when resultmessagesr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59967</th>\n",
       "      <td>hiwith cvs cocoon ive been getting warnings li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>error log shows the followingmessage found com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110268</th>\n",
       "      <td>when following the instructions for helloworld...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103694</th>\n",
       "      <td>rse server stop over ssh does not work for as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>currently there is no way to browse and discov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>i have a custom maven plugin that i wrote and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16608 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "16484   iiopsecurityinvocationtestcase fails with secu...      0\n",
       "27086   it seems that we have some jars as part of pdf...      1\n",
       "51630                              release olingo version      0\n",
       "54583   log cleaner grows buffers when resultmessagesr...      1\n",
       "59967   hiwith cvs cocoon ive been getting warnings li...      0\n",
       "...                                                   ...    ...\n",
       "76820   error log shows the followingmessage found com...      1\n",
       "110268  when following the instructions for helloworld...      1\n",
       "103694  rse server stop over ssh does not work for as ...      1\n",
       "860     currently there is no way to browse and discov...      0\n",
       "15795   i have a custom maven plugin that i wrote and ...      1\n",
       "\n",
       "[16608 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ee8cbdf-ad1c-41d6-a90c-b024f99b9e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    8334\n",
       "1    8274\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "690f08dd-983c-429c-a6b4-86c20e540b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HP_TestDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = df['text'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        truncation=True,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=self.max_len\n",
    "                    )\n",
    "        \n",
    "        samples = {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "            \n",
    "        }\n",
    "\n",
    "        if 'token_type_ids' in inputs:\n",
    "            samples['token_type_ids'] = inputs['token_type_ids']\n",
    "        \n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b437f36d-a3a6-4690-a4c5-7c8567b184c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorWithPadding(tokenizer=CONFIG['tokenizer'])\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "model = HP_Model(CONFIG['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c310d8ae-a37e-4eec-84ab-75cf6273df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_loader(test_df):    \n",
    "    test_dataset = HP_TestDataset(test_df, \n",
    "                                   tokenizer=CONFIG['tokenizer'], \n",
    "                                   max_length=CONFIG['max_length'])\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset, \n",
    "                             batch_size=CONFIG['valid_batch_size'], \n",
    "                             collate_fn=collate_fn, \n",
    "                             num_workers=2, \n",
    "                             shuffle=False, \n",
    "                             pin_memory=True, \n",
    "                             drop_last=False)\n",
    "    return test_loader\n",
    "\n",
    "test_loader = prepare_test_loader(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42c35623-2819-4bad-a2bc-6fde708a1420",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inference(test_loader, model, device):\n",
    "    preds = []\n",
    "    preds_target = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    bar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    \n",
    "    for step, data in bar: \n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        \n",
    "        output = model(ids, mask)\n",
    "        y_preds = softmax(torch.tensor(output.to('cpu'))).numpy()\n",
    "        pred_target = torch.argmax(output, dim=-1).flatten().tolist()\n",
    "        \n",
    "        preds.append(y_preds)\n",
    "        preds_target.append(pred_target) \n",
    "    predictions = np.concatenate(preds)\n",
    "    predictions_label = np.concatenate(preds_target)\n",
    "    return predictions , predictions_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "601c0907-fc9a-4ede-9836-ed7df661b947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HP_Model' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(state)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Prepare data loader if using PyTorch, else adjust according to your model requirements\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# For example purposes, let's assume a simple prediction without batches\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(TD_dataset\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Assuming 'label' is your target column\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Evaluate the predictions\u001b[39;00m\n\u001b[1;32m     17\u001b[0m actual_labels \u001b[38;5;241m=\u001b[39m TD_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HP_Model' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "deberta_predictions = []\n",
    "deberta_predictions_labels = []\n",
    "\n",
    "\n",
    "fold = 0\n",
    "\n",
    "print(\"Fold {}\".format(fold))\n",
    "    \n",
    "state = torch.load(f'{HASH_NAME}-Loss-Fold-{fold}.bin')\n",
    "model.load_state_dict(state)\n",
    "    \n",
    "# Prepare data loader if using PyTorch, else adjust according to your model requirements\n",
    "# For example purposes, let's assume a simple prediction without batches\n",
    "predictions = model.predict(TD_dataset.drop('label', axis=1))  # Assuming 'label' is your target column\n",
    "\n",
    "# Evaluate the predictions\n",
    "actual_labels = TD_dataset['label']\n",
    "print(classification_report(actual_labels, predictions))\n",
    "cf_matrix = confusion_matrix(actual_labels, predictions)\n",
    "print(cf_matrix)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ee418-5404-468e-88bd-18913c2d3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a364a-2e0f-4b27-9f77-c2925d3ce2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.mean(deberta_predictions, axis=0)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc393a64-0fb7-4f65-a69a-bdccddf89edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3348dbf-e8d9-46c0-be55-89592c29445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b2a1d7-8f4e-417d-9e02-570d4107feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"prediction_0\"] = predictions[:, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4c2333-024e-47ca-8828-5c5d19ad07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"prediction_1\"] = predictions[:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2fb4c-ec25-4df0-9d25-c2db6e09e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, CONFIG['n_fold']):\n",
    "\n",
    "    test_df[f\"prediction_label_fold_{i}\"] = deberta_predictions_labels[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4473d1d-6485-49e6-88bf-6aa3f05326cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68812cae-b8d4-4f6d-bee3-cb7a3ff24441",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c1731-776c-4105-90a1-5e9e6cb29b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Max'] = test_df[['prediction_0','prediction_1']].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb0e15-dc91-4785-adcd-bd9c1676d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"pred\"] = test_df['Max'].apply(lambda x: x.replace(\"prediction_0\", \"0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ef524d-f2f0-41d3-b0f1-3f61d47d5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"pred\"] = test_df['pred'].apply(lambda x: x.replace(\"prediction_1\", \"1\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72170b82-c414-41da-8f02-b41c13aa84cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"pred\"] = test_df[\"pred\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e7e7b-5712-4bae-b8fd-81586e97a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8ca5b-1611-400a-98ea-590e18e3e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(test_df[\"label\"].values, test_df[\"pred\"].values)\n",
    "\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ff2ad-0501-46c3-b5c8-7f414a2e7b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "ax = sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "\n",
    "ax.set_title('Jira: Highest vs rest\\n\\n NonHP vs HP \\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False(NonHP)','True(HP)'])\n",
    "ax.yaxis.set_ticklabels(['False(NonHP)','True(HP)'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9228c89-6cae-4a8e-a433-e7b5328dba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(classification_report(test_df[\"label\"].values, test_df[\"pred\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e0928e-90b4-48b3-be96-f3aa91e9ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# Calculate the Matthew's Correlation Coefficient\n",
    "mcc = matthews_corrcoef(test_df[\"label\"].values, test_df[\"pred\"].values)\n",
    "print(\"Matthew's Correlation Coefficient:\", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2df1a2-253f-4e67-9bad-a799f788b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "a64f21293159cd9c4e596ef7fd6c17a9c99d13712885c299cb3370e7a4d97830"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
