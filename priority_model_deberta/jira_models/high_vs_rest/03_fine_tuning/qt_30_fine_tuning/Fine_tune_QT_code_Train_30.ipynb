{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99249a9d-1abd-402b-ac83-e5d1264efb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 17:01:23] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 17:01:24] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 17:01:24] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 17:01:24] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 17:01:24] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 17:01:26] We saw that you have a AMD EPYC 7642 48-Core Processor but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 17:01:26] CPU Model on constant consumption mode: AMD EPYC 7642 48-Core Processor\n",
      "[codecarbon INFO @ 17:01:26] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 17:01:26]   Platform system: Linux-5.14.0-362.8.1.el9_3.x86_64-x86_64-with-glibc2.34\n",
      "[codecarbon INFO @ 17:01:26]   Python version: 3.11.3\n",
      "[codecarbon INFO @ 17:01:26]   CodeCarbon version: 2.3.4\n",
      "[codecarbon INFO @ 17:01:26]   Available RAM : 256.000 GB\n",
      "[codecarbon INFO @ 17:01:26]   CPU count: 24\n",
      "[codecarbon INFO @ 17:01:26]   CPU model: AMD EPYC 7642 48-Core Processor\n",
      "[codecarbon INFO @ 17:01:26]   GPU count: 1\n",
      "[codecarbon INFO @ 17:01:26]   GPU model: 1 x NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "from codecarbon import EmissionsTracker\n",
    "import logging\n",
    "output_directory = \"/fp/homes01/u01/ec-krimhau/thesis_code/\"\n",
    "\n",
    "tracker = EmissionsTracker(output_dir=output_directory)\n",
    "tracker.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a29e554f-5f00-426e-afa1-a3b54dab7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('codecarbon').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c4206f-a9dc-470b-bb55-415584f2116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import joblib\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "\n",
    "# For Transformer Models\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, AdamW\n",
    "from transformers import DataCollatorWithPadding\n",
    "import datasets\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import wandb\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f8979d-d850-4977-8dda-971ac6eea3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env file\n",
    "%load_ext dotenv\n",
    "%dotenv /fp/homes01/u01/ec-krimhau/thesis_code/.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "677223cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /fp/homes01/u01/ec-krimhau/thesis_code/jira/priority_model/highest_vs_rest/deberta/01_training/01_train_highest_vs_rest.ipynb.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhaugerud-kristian\u001b[0m (\u001b[33mkrimhau\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /fp/homes01/u01/ec-krimhau/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = '/fp/homes01/u01/ec-krimhau/thesis_code/jira/priority_model/highest_vs_rest/deberta/01_training/01_train_highest_vs_rest.ipynb'\n",
    "# Get wandb api key from .env file\n",
    "wandb_api_key = os.getenv('WANDB_API_KEY')\n",
    "# Login to wandb to track results\n",
    "wandb.login(key = wandb_api_key) # API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7fcade8-1e6d-418a-acd1-c860be6c3c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vioyhv418swq\n"
     ]
    }
   ],
   "source": [
    "def id_generator(size=12, chars=string.ascii_lowercase + string.digits):\n",
    "    return ''.join(random.SystemRandom().choice(chars) for _ in range(size))\n",
    "\n",
    "\n",
    "HASH_NAME = id_generator(size=12)\n",
    "print(HASH_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec0aa632-8739-4e63-bde0-5f4fc123f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\"seed\": 42,\n",
    "          \"epochs\": 3,\n",
    "          \"model_name\": \"microsoft/deberta-v3-base\",\n",
    "          \"train_batch_size\": 8,\n",
    "          \"valid_batch_size\": 16,\n",
    "          \"max_length\": 512,\n",
    "          \"learning_rate\": 1e-5,\n",
    "          \"scheduler\": 'CosineAnnealingLR',\n",
    "          \"min_lr\": 1e-6,\n",
    "          \"T_max\": 500,\n",
    "          \"weight_decay\": 1e-6,\n",
    "          \"n_fold\": 3,\n",
    "          \"n_accumulate\": 1,\n",
    "          \"num_classes\": 2,\n",
    "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "          \"hash_name\": HASH_NAME,\n",
    "          \"_wandb_kernel\": \"deb\",\n",
    "          }\n",
    "\n",
    "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n",
    "CONFIG['group'] = f'{HASH_NAME}-Baseline'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31dc5cac-8438-438d-b45b-e2dab3b74949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5220e6af-9036-4a04-8808-b374d2c8728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_percent=.85, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    test = df.iloc[perm[train_end:]]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "179c96ee-42ea-42eb-bb1b-242173a38663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "      <th>class_original</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>highest</th>\n",
       "      <td>when we do range query on simple keys it does ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highest</th>\n",
       "      <td>unhandledpromiserejectionwarning unhandled pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>Highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>the fabricunittestdaily branch failing intermi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>as a system operator i want to receive alerts ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>there is no support in datasourcetransactionma...</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>once i have imported a widget into the store i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>the spec defines an axiom of a ie singleton li...</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>to have an history on master of all csvs setup...</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highest</th>\n",
       "      <td>there are still some changes expected to be me...</td>\n",
       "      <td>1</td>\n",
       "      <td>Highest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highest</th>\n",
       "      <td>crw failed to install from operatorhub because...</td>\n",
       "      <td>1</td>\n",
       "      <td>Highest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110716 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text_clean  label  \\\n",
       "class                                                               \n",
       "highest  when we do range query on simple keys it does ...      1   \n",
       "highest  unhandledpromiserejectionwarning unhandled pro...      1   \n",
       "rest     the fabricunittestdaily branch failing intermi...      0   \n",
       "rest     as a system operator i want to receive alerts ...      0   \n",
       "rest     there is no support in datasourcetransactionma...      0   \n",
       "...                                                    ...    ...   \n",
       "rest     once i have imported a widget into the store i...      0   \n",
       "rest     the spec defines an axiom of a ie singleton li...      0   \n",
       "rest     to have an history on master of all csvs setup...      0   \n",
       "highest  there are still some changes expected to be me...      1   \n",
       "highest  crw failed to install from operatorhub because...      1   \n",
       "\n",
       "        class_original  \n",
       "class                   \n",
       "highest        Highest  \n",
       "highest        Highest  \n",
       "rest            Medium  \n",
       "rest            Medium  \n",
       "rest            Medium  \n",
       "...                ...  \n",
       "rest               Low  \n",
       "rest            Medium  \n",
       "rest            Medium  \n",
       "highest        Highest  \n",
       "highest        Highest  \n",
       "\n",
       "[110716 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_training_df = pd.read_csv(\"../../csv/highest_vs_rest_balanced_jira.csv\" , index_col = 0)\n",
    "full_training_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7de7d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop NaN values and reset index of dataframe\n",
    "full_training_df = full_training_df[full_training_df['text_clean'].notna()]\n",
    "full_training_df = full_training_df.rename(columns={'text_clean': 'text'})\n",
    "full_training_df = full_training_df.reset_index()\n",
    "full_training_df.drop(columns=[\"class\", \"class_original\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29268f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when we do range query on simple keys it does ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unhandledpromiserejectionwarning unhandled pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the fabricunittestdaily branch failing intermi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>as a system operator i want to receive alerts ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there is no support in datasourcetransactionma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110711</th>\n",
       "      <td>once i have imported a widget into the store i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110712</th>\n",
       "      <td>the spec defines an axiom of a ie singleton li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110713</th>\n",
       "      <td>to have an history on master of all csvs setup...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110714</th>\n",
       "      <td>there are still some changes expected to be me...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110715</th>\n",
       "      <td>crw failed to install from operatorhub because...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110716 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "0       when we do range query on simple keys it does ...      1\n",
       "1       unhandledpromiserejectionwarning unhandled pro...      1\n",
       "2       the fabricunittestdaily branch failing intermi...      0\n",
       "3       as a system operator i want to receive alerts ...      0\n",
       "4       there is no support in datasourcetransactionma...      0\n",
       "...                                                   ...    ...\n",
       "110711  once i have imported a widget into the store i...      0\n",
       "110712  the spec defines an axiom of a ie singleton li...      0\n",
       "110713  to have an history on master of all csvs setup...      0\n",
       "110714  there are still some changes expected to be me...      1\n",
       "110715  crw failed to install from operatorhub because...      1\n",
       "\n",
       "[110716 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38bd7fa7-7b96-4934-b210-2b4a63881828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>using this example run via qmlscene code impor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if i happen to get two modal dialogs open at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the attached screenshot shows that the zapfino...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello i have some issues with mysqlopenssl lib...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we have a few updates to webkit that the webki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>this was actually with the packageto reproduce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>a fairly sure way to cause this crash is to in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>it seems every example in the dev branch curre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>the style seems to have a few rough edgesthere...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>steps to repro create new presentation add a l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3882 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_clean  label\n",
       "0     using this example run via qmlscene code impor...      0\n",
       "1     if i happen to get two modal dialogs open at t...      1\n",
       "2     the attached screenshot shows that the zapfino...      0\n",
       "3     hello i have some issues with mysqlopenssl lib...      0\n",
       "4     we have a few updates to webkit that the webki...      1\n",
       "...                                                 ...    ...\n",
       "3877  this was actually with the packageto reproduce...      1\n",
       "3878  a fairly sure way to cause this crash is to in...      1\n",
       "3879  it seems every example in the dev branch curre...      1\n",
       "3880  the style seems to have a few rough edgesthere...      0\n",
       "3881  steps to repro create new presentation add a l...      0\n",
       "\n",
       "[3882 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fine_tuning_df = pd.read_csv(\"../../csv/clean_Qt_balanced.csv\")\n",
    "fine_tuning_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb7f500a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>using this example run via qmlscene code impor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if i happen to get two modal dialogs open at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the attached screenshot shows that the zapfino...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hello i have some issues with mysqlopenssl lib...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we have a few updates to webkit that the webki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>this was actually with the packageto reproduce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>a fairly sure way to cause this crash is to in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>it seems every example in the dev branch curre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>the style seems to have a few rough edgesthere...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>steps to repro create new presentation add a l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3882 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     using this example run via qmlscene code impor...      0\n",
       "1     if i happen to get two modal dialogs open at t...      1\n",
       "2     the attached screenshot shows that the zapfino...      0\n",
       "3     hello i have some issues with mysqlopenssl lib...      0\n",
       "4     we have a few updates to webkit that the webki...      1\n",
       "...                                                 ...    ...\n",
       "3877  this was actually with the packageto reproduce...      1\n",
       "3878  a fairly sure way to cause this crash is to in...      1\n",
       "3879  it seems every example in the dev branch curre...      1\n",
       "3880  the style seems to have a few rough edgesthere...      0\n",
       "3881  steps to repro create new presentation add a l...      0\n",
       "\n",
       "[3882 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fine_tuning_df = fine_tuning_df.rename(columns={'text_clean': 'text'})\n",
    "fine_tuning_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abede05d-ccb8-427c-b64a-135ba811adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the full training dataframe into training and test dataframes\n",
    "# 85/15 split. Validation set will be created from the training set later.\n",
    "train_full_training_df, test_full_training_df = train_test_split(full_training_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ba5200b-d0af-4cc0-9d9c-7ae701d07b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the fine-tuning data frame into training and test data frames\n",
    "# Where 30% of the data is used for training and 70% for testing\n",
    "fine_tune_train_df , fine_tune_test_df = train_test_split(fine_tuning_df, train_percent=.30) # 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2acee4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3432</th>\n",
       "      <td>mingw version of gcc bundled with qt has a ver...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>pressing a button inside a mousearea and then ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>due to a malfunctioning script all the fastfor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3614</th>\n",
       "      <td>introduced by change</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>codejava import qtquick text textformat textpl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>building existing project eg any example in wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>noformat fail tstcontrolstestopenduringexittra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>creation of work items failed most recent call...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>there is no way to propagate errors from an im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>noformat srcqmldevtoolscmakefilesqmldevtoolspr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "3432  mingw version of gcc bundled with qt has a ver...      1\n",
       "1018  pressing a button inside a mousearea and then ...      0\n",
       "1941  due to a malfunctioning script all the fastfor...      1\n",
       "3614                               introduced by change      1\n",
       "1200  codejava import qtquick text textformat textpl...      0\n",
       "...                                                 ...    ...\n",
       "1171  building existing project eg any example in wi...      1\n",
       "1295  noformat fail tstcontrolstestopenduringexittra...      0\n",
       "361   creation of work items failed most recent call...      1\n",
       "135   there is no way to propagate errors from an im...      0\n",
       "1134  noformat srcqmldevtoolscmakefilesqmldevtoolspr...      1\n",
       "\n",
       "[1164 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f13fa85a-e5f6-4aec-9592-3f60f514f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the training dataframes into the final training dataframe\n",
    "df = pd.concat([train_full_training_df, fine_tune_train_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1b91f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>currently we are using usrshareelasticsearch a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>its been over hrs since the mirror has been up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there has been discussion on the mailing lists...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when elytron client tries to obtain clientconf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>need to be able to release all items at once v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95267</th>\n",
       "      <td>building existing project eg any example in wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95268</th>\n",
       "      <td>noformat fail tstcontrolstestopenduringexittra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95269</th>\n",
       "      <td>creation of work items failed most recent call...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95270</th>\n",
       "      <td>there is no way to propagate errors from an im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95271</th>\n",
       "      <td>noformat srcqmldevtoolscmakefilesqmldevtoolspr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95272 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      currently we are using usrshareelasticsearch a...      0\n",
       "1      its been over hrs since the mirror has been up...      0\n",
       "2      there has been discussion on the mailing lists...      0\n",
       "3      when elytron client tries to obtain clientconf...      1\n",
       "4      need to be able to release all items at once v...      1\n",
       "...                                                  ...    ...\n",
       "95267  building existing project eg any example in wi...      1\n",
       "95268  noformat fail tstcontrolstestopenduringexittra...      0\n",
       "95269  creation of work items failed most recent call...      1\n",
       "95270  there is no way to propagate errors from an im...      0\n",
       "95271  noformat srcqmldevtoolscmakefilesqmldevtoolspr...      1\n",
       "\n",
       "[95272 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1902e2d0-9479-4a54-9148-7b6ddd0e44e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=CONFIG['n_fold'])\n",
    "\n",
    "for fold, ( _, val_) in enumerate(gkf.split(X=df, groups=df.text)):\n",
    "    df.loc[val_ , \"kfold\"] = int(fold)\n",
    "    \n",
    "df[\"kfold\"] = df[\"kfold\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60874b39-4bec-4d96-9973-01d6935693dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kfold  label\n",
       "0      1        16059\n",
       "       0        15699\n",
       "1      0        15987\n",
       "       1        15770\n",
       "2      0        15903\n",
       "       1        15854\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('kfold')['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "455d058b-1561-4493-bd19-11cb59be06cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>currently we are using usrshareelasticsearch a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>its been over hrs since the mirror has been up...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there has been discussion on the mailing lists...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when elytron client tries to obtain clientconf...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>need to be able to release all items at once v...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95267</th>\n",
       "      <td>building existing project eg any example in wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95268</th>\n",
       "      <td>noformat fail tstcontrolstestopenduringexittra...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95269</th>\n",
       "      <td>creation of work items failed most recent call...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95270</th>\n",
       "      <td>there is no way to propagate errors from an im...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95271</th>\n",
       "      <td>noformat srcqmldevtoolscmakefilesqmldevtoolspr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95272 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  kfold\n",
       "0      currently we are using usrshareelasticsearch a...      0      1\n",
       "1      its been over hrs since the mirror has been up...      0      2\n",
       "2      there has been discussion on the mailing lists...      0      0\n",
       "3      when elytron client tries to obtain clientconf...      1      2\n",
       "4      need to be able to release all items at once v...      1      1\n",
       "...                                                  ...    ...    ...\n",
       "95267  building existing project eg any example in wi...      1      0\n",
       "95268  noformat fail tstcontrolstestopenduringexittra...      0      2\n",
       "95269  creation of work items failed most recent call...      1      1\n",
       "95270  there is no way to propagate errors from an im...      0      2\n",
       "95271  noformat srcqmldevtoolscmakefilesqmldevtoolspr...      1      0\n",
       "\n",
       "[95272 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2e6cfb2-d1e2-4ef8-8694-2d18e56296a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HP_Dataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = df['text'].values\n",
    "        self.targets = df['label'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        truncation=True,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=self.max_len\n",
    "                    )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "            'target': self.targets[index]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbc28466-4efa-44b1-9486-63cc0b2d7c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorWithPadding(tokenizer=CONFIG['tokenizer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d739c680-fc15-4d64-8cf4-8902174dfe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dba820b1-375c-4a0c-970a-fd554c94ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HP_Model(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(HP_Model, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.pooler = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, CONFIG['num_classes'])\n",
    "        \n",
    "    def forward(self, ids, mask):        \n",
    "        out = self.model(input_ids=ids,attention_mask=mask,\n",
    "                         output_hidden_states=False)\n",
    "        out = self.pooler(out.last_hidden_state, mask)\n",
    "        out = self.drop(out)\n",
    "        outputs = self.fc(out)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1abf13ca-1c86-4cfe-9955-3ff4d0cafe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, labels):\n",
    "    return nn.CrossEntropyLoss()(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "013d660f-6376-45cf-9c52-2de074708b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        targets = data['target'].to(device, dtype=torch.long)\n",
    "        \n",
    "        batch_size = ids.size(0)\n",
    "\n",
    "        outputs = model(ids, mask)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "        loss.backward()\n",
    "    \n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "            optimizer.step()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77809ed9-c4a1-436f-9bc5-d806ffe6d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2df79ea9-afa8-4de5-a84b-d6dfdc826ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_classification_report(y_true, y_pred, target_names = ['Non_HP', 'HP'], digits=4):\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, target_names = target_names, digits=4))\n",
    "    \n",
    "    accuracy =round(accuracy_score(y_true, y_pred),4)\n",
    "    print(\"Accuracy =\",  accuracy)\n",
    "    f1score = round(f1_score(y_true, y_pred),4)\n",
    "    print(\"F1_score =\", f1score)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['Non_HP', 'HP'])\n",
    "    ax.yaxis.set_ticklabels(['Non_HP', 'HP'])\n",
    "    \n",
    "    return  accuracy , f1score\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0633e6f-e935-4b94-853b-f3ef01cf97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        targets = data['target'].to(device, dtype=torch.long)\n",
    "        \n",
    "        batch_size = ids.size(0)\n",
    "\n",
    "        outputs = model(ids, mask)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "\n",
    "        predictions = torch.argmax(outputs, dim=-1).flatten().tolist()\n",
    "        \n",
    "        target = targets.tolist()\n",
    "\n",
    "        y_pred.extend(predictions)\n",
    "        y_true.extend(target)\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    \n",
    "    accuracy, f1score = all_classification_report(y_true,y_pred)\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss , accuracy , f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2a01d01-3b43-4723-9874-43b38ffcbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n",
    "    # To automatically log gradients\n",
    "    wandb.watch(model, log_freq=100)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_loss = np.inf\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch)\n",
    "        \n",
    "        val_epoch_loss, accuracy , f1score = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "      \n",
    "        history['Valid accuracy'].append(accuracy)\n",
    "        history['Valid f1score'].append(f1score)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # Log the metrics\n",
    "        wandb.log({\"Train Loss\": train_epoch_loss})\n",
    "        wandb.log({\"Valid Loss\": val_epoch_loss})\n",
    "        wandb.log({\"Valid Accuracy\": accuracy})\n",
    "        wandb.log({\"Valid F1_score\": f1score})\n",
    "\n",
    "\n",
    "        \n",
    "        # deep copy the model\n",
    "        if val_epoch_loss <= best_epoch_loss:\n",
    "            print(f\"{b_}Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
    "            best_epoch_loss = val_epoch_loss\n",
    "            run.summary[\"Best Loss\"] = best_epoch_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"{HASH_NAME}-Loss-Fold-{fold}.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ac45314-e0b4-4150-8e2a-06beba582112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = HP_Dataset(df_train, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "    valid_dataset = HP_Dataset(df_valid, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], collate_fn=collate_fn, \n",
    "                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], collate_fn=collate_fn,\n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3b81685-ab3f-47ca-b1de-86dc9d79fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d0841-320f-4794-8377-ce2073b72bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m====== Fold: 0 ======\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/fp/homes01/u01/ec-krimhau/thesis_code/priority_model_deberta/jira_models/high_vs_rest/03_fine_tuning/qt_30_fine_tuning/wandb/run-20240403_170156-ubmqac67</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/krimhau/HP_results_Jira_High_vs_rest_results/runs/ubmqac67' target=\"_blank\">vioyhv418swq-fold-0</a></strong> to <a href='https://wandb.ai/krimhau/HP_results_Jira_High_vs_rest_results' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/krimhau/HP_results_Jira_High_vs_rest_results' target=\"_blank\">https://wandb.ai/krimhau/HP_results_Jira_High_vs_rest_results</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/krimhau/HP_results_Jira_High_vs_rest_results/runs/ubmqac67' target=\"_blank\">https://wandb.ai/krimhau/HP_results_Jira_High_vs_rest_results/runs/ubmqac67</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA A100-PCIE-40GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7939/7939 [30:11<00:00,  4.38it/s, Epoch=1, LR=9.67e-6, Train_Loss=0.609]\n",
      "100%|██████████| 1985/1985 [04:18<00:00,  7.69it/s, Epoch=1, LR=9.67e-6, Valid_Loss=0.575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Non_HP     0.7197    0.6464    0.6811     15699\n",
      "          HP     0.6856    0.7539    0.7182     16059\n",
      "\n",
      "    accuracy                         0.7008     31758\n",
      "   macro avg     0.7027    0.7002    0.6996     31758\n",
      "weighted avg     0.7025    0.7008    0.6998     31758\n",
      "\n",
      "Accuracy = 0.7008\n",
      "F1_score = 0.7182\n",
      "\u001b[34mValidation Loss Improved (inf ---> 0.5746044465663549)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7939/7939 [29:48<00:00,  4.44it/s, Epoch=2, LR=8.74e-6, Train_Loss=0.556]\n",
      "100%|██████████| 1985/1985 [04:17<00:00,  7.69it/s, Epoch=2, LR=8.74e-6, Valid_Loss=0.594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Non_HP     0.6346    0.7834    0.7012     15699\n",
      "          HP     0.7252    0.5590    0.6314     16059\n",
      "\n",
      "    accuracy                         0.6699     31758\n",
      "   macro avg     0.6799    0.6712    0.6663     31758\n",
      "weighted avg     0.6804    0.6699    0.6659     31758\n",
      "\n",
      "Accuracy = 0.6699\n",
      "F1_score = 0.6314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7939/7939 [29:50<00:00,  4.43it/s, Epoch=3, LR=7.34e-6, Train_Loss=0.515]\n",
      "100%|██████████| 1985/1985 [04:18<00:00,  7.68it/s, Epoch=3, LR=7.34e-6, Valid_Loss=0.574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Non_HP     0.7172    0.6926    0.7047     15699\n",
      "          HP     0.7092    0.7330    0.7209     16059\n",
      "\n",
      "    accuracy                         0.7130     31758\n",
      "   macro avg     0.7132    0.7128    0.7128     31758\n",
      "weighted avg     0.7132    0.7130    0.7129     31758\n",
      "\n",
      "Accuracy = 0.713\n",
      "F1_score = 0.7209\n",
      "\u001b[34mValidation Loss Improved (0.5746044465663549 ---> 0.5741667391949228)\n",
      "Model Saved\u001b[0m\n",
      "\n",
      "Training complete in 1h 42m 50s\n",
      "Best Loss: 0.5742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.021 MB of 0.021 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Loss</td><td>█▄▁</td></tr><tr><td>Valid Accuracy</td><td>▆▁█</td></tr><tr><td>Valid F1_score</td><td>█▁█</td></tr><tr><td>Valid Loss</td><td>▁█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Best Loss</td><td>0.57417</td></tr><tr><td>Train Loss</td><td>0.51493</td></tr><tr><td>Valid Accuracy</td><td>0.713</td></tr><tr><td>Valid F1_score</td><td>0.7209</td></tr><tr><td>Valid Loss</td><td>0.57417</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vioyhv418swq-fold-0</strong> at: <a href='https://wandb.ai/krimhau/HP_results_Jira_High_vs_rest_results/runs/ubmqac67' target=\"_blank\">https://wandb.ai/krimhau/HP_results_Jira_High_vs_rest_results/runs/ubmqac67</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240403_170156-ubmqac67/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m====== Fold: 1 ======\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfde8c86f36241f69f9d4a8a897de552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0111137254215363, max=1.0))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/fp/homes01/u01/ec-krimhau/thesis_code/priority_model_deberta/jira_models/high_vs_rest/03_fine_tuning/qt_30_fine_tuning/wandb/run-20240403_184501-z93b12s6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/krimhau/HP_results_Jira_High_vs_rest_results/runs/z93b12s6' target=\"_blank\">vioyhv418swq-fold-1</a></strong> to <a href='https://wandb.ai/krimhau/HP_results_Jira_High_vs_rest_results' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/krimhau/HP_results_Jira_High_vs_rest_results' target=\"_blank\">https://wandb.ai/krimhau/HP_results_Jira_High_vs_rest_results</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/krimhau/HP_results_Jira_High_vs_rest_results/runs/z93b12s6' target=\"_blank\">https://wandb.ai/krimhau/HP_results_Jira_High_vs_rest_results/runs/z93b12s6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA A100-PCIE-40GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7939/7939 [30:17<00:00,  4.37it/s, Epoch=1, LR=9.67e-6, Train_Loss=0.61] \n",
      "100%|██████████| 1985/1985 [04:21<00:00,  7.59it/s, Epoch=1, LR=9.67e-6, Valid_Loss=0.579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Non_HP     0.6736    0.7449    0.7075     15987\n",
      "          HP     0.7103    0.6341    0.6700     15770\n",
      "\n",
      "    accuracy                         0.6899     31757\n",
      "   macro avg     0.6919    0.6895    0.6887     31757\n",
      "weighted avg     0.6918    0.6899    0.6889     31757\n",
      "\n",
      "Accuracy = 0.6899\n",
      "F1_score = 0.67\n",
      "\u001b[34mValidation Loss Improved (inf ---> 0.579076858104302)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7939/7939 [30:20<00:00,  4.36it/s, Epoch=2, LR=8.74e-6, Train_Loss=0.56] \n",
      "100%|██████████| 1985/1985 [04:21<00:00,  7.59it/s, Epoch=2, LR=8.74e-6, Valid_Loss=0.573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Non_HP     0.7666    0.5528    0.6424     15987\n",
      "          HP     0.6466    0.8294    0.7267     15770\n",
      "\n",
      "    accuracy                         0.6901     31757\n",
      "   macro avg     0.7066    0.6911    0.6845     31757\n",
      "weighted avg     0.7070    0.6901    0.6842     31757\n",
      "\n",
      "Accuracy = 0.6901\n",
      "F1_score = 0.7267\n",
      "\u001b[34mValidation Loss Improved (0.579076858104302 ---> 0.5729555103262842)\n",
      "Model Saved\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1823/7939 [06:57<30:23,  3.35it/s, Epoch=3, LR=4.14e-6, Train_Loss=0.524]"
     ]
    }
   ],
   "source": [
    "for fold in range(0, CONFIG['n_fold']):\n",
    "    print(f\"{y_}====== Fold: {fold} ======{sr_}\")\n",
    "    run = wandb.init(project='HP_results_Jira_High_vs_rest_results', \n",
    "                     config=CONFIG,\n",
    "                     job_type='Train',\n",
    "                     group=CONFIG['group'],\n",
    "                     tags=[CONFIG['model_name'], f'{HASH_NAME}'],\n",
    "                     name=f'{HASH_NAME}-fold-{fold}',\n",
    "                     anonymous='must')\n",
    "    \n",
    "    # Create Dataloaders\n",
    "    train_loader, valid_loader = prepare_loaders(fold=fold)\n",
    "    \n",
    "    model = HP_Model(CONFIG['model_name'])\n",
    "    model.to(CONFIG['device'])\n",
    "    \n",
    "    # Define Optimizer and Scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    \n",
    "    model, history = run_training(model, optimizer, scheduler,\n",
    "                                  device=CONFIG['device'],\n",
    "                                  num_epochs=CONFIG['epochs'],\n",
    "                                  fold=fold)\n",
    "    \n",
    "    run.finish()\n",
    "    \n",
    "    del model, history, train_loader, valid_loader\n",
    "    _ = gc.collect()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b5b4c",
   "metadata": {},
   "source": [
    "<h2> Testing Inference </h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f36497-0ef8-4e3c-8c9e-50c92b92e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings,transformers,logging,torch\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b25e683-7c36-487f-ba36-905d9b04ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = fine_tune_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be00e4-81ad-4264-b42a-afff577eff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f08dd-983c-429c-a6b4-86c20e540b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HP_TestDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = df['text'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "                        text,\n",
    "                        truncation=True,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=self.max_len\n",
    "                    )\n",
    "        \n",
    "        samples = {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "            \n",
    "        }\n",
    "\n",
    "        if 'token_type_ids' in inputs:\n",
    "            samples['token_type_ids'] = inputs['token_type_ids']\n",
    "        \n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b437f36d-a3a6-4690-a4c5-7c8567b184c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorWithPadding(tokenizer=CONFIG['tokenizer'])\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "model = HP_Model(CONFIG['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310d8ae-a37e-4eec-84ab-75cf6273df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_loader(test_df):    \n",
    "    test_dataset = HP_TestDataset(test_df, \n",
    "                                   tokenizer=CONFIG['tokenizer'], \n",
    "                                   max_length=CONFIG['max_length'])\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset, \n",
    "                             batch_size=CONFIG['valid_batch_size'], \n",
    "                             collate_fn=collate_fn, \n",
    "                             num_workers=2, \n",
    "                             shuffle=False, \n",
    "                             pin_memory=True, \n",
    "                             drop_last=False)\n",
    "    return test_loader\n",
    "\n",
    "test_loader = prepare_test_loader(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c35623-2819-4bad-a2bc-6fde708a1420",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inference(test_loader, model, device):\n",
    "    preds = []\n",
    "    preds_target = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    bar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    \n",
    "    for step, data in bar: \n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        \n",
    "        output = model(ids, mask)\n",
    "        y_preds = softmax(torch.tensor(output.to('cpu'))).numpy()\n",
    "        pred_target = torch.argmax(output, dim=-1).flatten().tolist()\n",
    "        \n",
    "        preds.append(y_preds)\n",
    "        preds_target.append(pred_target) \n",
    "    predictions = np.concatenate(preds)\n",
    "    predictions_label = np.concatenate(preds_target)\n",
    "    return predictions , predictions_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9ceb3-2116-4b8d-94a1-abd27e314c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the HASH_NAME according to new generated hash for your run\n",
    "#HASH_NAME = \"ekgx4wmexn91\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601c0907-fc9a-4ede-9836-ed7df661b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_predictions = []\n",
    "deberta_predictions_labels = []\n",
    "\n",
    "\n",
    "\n",
    "for fold in range(0, CONFIG['n_fold']):\n",
    "    print(\"Fold {}\".format(fold))\n",
    "    \n",
    "    state = torch.load(f'{HASH_NAME}-Loss-Fold-{fold}.bin')\n",
    "    model.load_state_dict(state)\n",
    "    \n",
    "    prediction, predictions_label = inference(test_loader, model, CONFIG['device'])\n",
    "    deberta_predictions.append(prediction)\n",
    "    deberta_predictions_labels.append(predictions_label)\n",
    "    del state, prediction; gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ee418-5404-468e-88bd-18913c2d3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a364a-2e0f-4b27-9f77-c2925d3ce2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.mean(deberta_predictions, axis=0)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc393a64-0fb7-4f65-a69a-bdccddf89edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3348dbf-e8d9-46c0-be55-89592c29445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b2a1d7-8f4e-417d-9e02-570d4107feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"prediction_0\"] = predictions[:, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4c2333-024e-47ca-8828-5c5d19ad07cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"prediction_1\"] = predictions[:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2fb4c-ec25-4df0-9d25-c2db6e09e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, CONFIG['n_fold']):\n",
    "\n",
    "    test_df[f\"prediction_label_fold_{i}\"] = deberta_predictions_labels[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4473d1d-6485-49e6-88bf-6aa3f05326cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68812cae-b8d4-4f6d-bee3-cb7a3ff24441",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c1731-776c-4105-90a1-5e9e6cb29b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Max'] = test_df[['prediction_0','prediction_1']].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb0e15-dc91-4785-adcd-bd9c1676d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"pred\"] = test_df['Max'].apply(lambda x: x.replace(\"prediction_0\", \"0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ef524d-f2f0-41d3-b0f1-3f61d47d5448",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"pred\"] = test_df['pred'].apply(lambda x: x.replace(\"prediction_1\", \"1\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72170b82-c414-41da-8f02-b41c13aa84cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"pred\"] = test_df[\"pred\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e7e7b-5712-4bae-b8fd-81586e97a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8ca5b-1611-400a-98ea-590e18e3e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(test_df[\"label\"].values, test_df[\"pred\"].values)\n",
    "\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ff2ad-0501-46c3-b5c8-7f414a2e7b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "ax = sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "\n",
    "ax.set_title('Jira: Jira fine tuning \\n\\nNonHP vs HP \\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False(NonHP)','True(HP)'])\n",
    "ax.yaxis.set_ticklabels(['False(NonHP)','True(HP)'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9228c89-6cae-4a8e-a433-e7b5328dba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(classification_report(test_df[\"label\"].values, test_df[\"pred\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a155c0-14f8-4918-8b58-8ebc91c06d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[[\"text\",\"label\",\"pred\"]].to_csv(\"MongoDB_70_Test_inference.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347de704-da8f-415a-bb42-eee04effbd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "a64f21293159cd9c4e596ef7fd6c17a9c99d13712885c299cb3370e7a4d97830"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
